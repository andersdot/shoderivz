{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a simple harmonic oscillator and trying to infer the spring constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as so\n",
    "%matplotlib inline\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad  \n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import autograph\n",
    "import tfleapfrog_copy as tflf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genData(x, v, npoints, std_noise_x, std_noise_v):\n",
    "    noise_x = np.random.normal(0, std_noise_x, len(x))\n",
    "    noise_v = np.random.normal(0, std_noise_v, len(x))\n",
    "    return noise_x + x, noise_v + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_likelihood(theta, data, dt_model):\n",
    "    chi2 = 0\n",
    "    k, x0, v0, *t_obs = theta\n",
    "    x_obs, v_obs, sigma_x, sigma_v = data\n",
    "    x, v = leapfrog(x0, v0, np.array(t_obs), phi_grad, dt, k=k)\n",
    "    chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "    chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "    return 0.5*chi2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_and_grad_py(position, k=1.0):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * k * position**2, k*position\n",
    "\n",
    "def leap(position, momentum, grad, potential_and_grad, step_size, k=1.0):\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    position += step_size * momentum\n",
    "    potential, grad = potential_and_grad_py(position, k=k)\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    return position, momentum, potential, grad\n",
    "\n",
    "def leapfrog(x0, v0, t_obs, potential_and_grad_py, dt, k=1.0):\n",
    "    #function that takes initial conditions that takes us to the next position \n",
    "    x = [] \n",
    "    v = [] \n",
    "    t = [] \n",
    "    grads = []\n",
    "    dts  = []\n",
    "    time = []\n",
    "    \n",
    "    tprime = 0.0\n",
    "    xprime = x0\n",
    "    vprime = v0\n",
    "    pot, grad = potential_and_grad_py(xprime, k=k)\n",
    "    for to in t_obs:\n",
    "\n",
    "        while tprime + dt < to:\n",
    "            xprime, vprime, pot, grad = leap(xprime, vprime, grad, potential_and_grad_py, dt, k=k)\n",
    "            tprime = tprime + dt    \n",
    "        dt_tiny = to - tprime\n",
    "        xsave, vsave, potsave, gradsave = leap(xprime, vprime, grad, potential_and_grad_py, dt_tiny, k=k)\n",
    "        tsave = tprime + dt_tiny\n",
    "        #print(xsave, vsave, tsave, potsave, gradsave)\n",
    "        x.append(xsave.copy())\n",
    "        v.append(vsave.copy())\n",
    "        t.append(tsave.copy())\n",
    "        grads.append(grad)\n",
    "        dts.append(dt_tiny.copy())\n",
    "        time.append(tprime)\n",
    "        #print(x, v)\n",
    "    return np.array(x), np.array(v), np.array(grads), np.array(dts), np.array(time) #, np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_true   = 100.\n",
    "v0_true   = 100.\n",
    "k_true    = 10.\n",
    "\n",
    "max_time  = np.float64(10.)\n",
    "\n",
    "nobspoints = 10\n",
    "std_noise_x = 10.0\n",
    "std_noise_v = 10.0\n",
    "\n",
    "plot_xerr = np.zeros(nobspoints) + std_noise_x\n",
    "plot_yerr = np.zeros(nobspoints) + std_noise_v\n",
    "t_obs_true = np.random.uniform(0, max_time, nobspoints)\n",
    "t_obs_true.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14374817e-03, 9.23385948e-01, 1.46755891e+00, 1.86260211e+00,\n",
       "       3.02332573e+00, 3.45560727e+00, 3.96767474e+00, 4.17022005e+00,\n",
       "       5.38816734e+00, 7.20324493e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_obs_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define step size of each leap and number of shos\n",
    "s_size = np.float64(0.01)      #resolution of each leap\n",
    "n_shos = 1            #number of simple harmonic oscillators \n",
    "\n",
    "#generate initial velocities and momenta\n",
    "#\n",
    "position_value = np.float64(np.random.randn(n_shos))\n",
    "momentum_value = np.float64(np.random.randn(n_shos))\n",
    "\n",
    "#set spring constant\n",
    "k_val = np.float64(0.0)\n",
    "t_previous_value = np.float64(0.0)\n",
    "x_value = np.float64(0.0)\n",
    "y_value = np.float64(0.0)\n",
    "#generate initial times to model SHO\n",
    "t_obs_init = t_obs_true #np.random.uniform(0, max_time, nobspoints)\n",
    "t_obs_init.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate true values and noisify them\n",
    "x_true, v_true, grad_true, dt_tiny_true, time_steps_true = leapfrog(x0_true, v0_true, t_obs_true, potential_and_grad_py, s_size, k=k_true)\n",
    "x_obs, v_obs = genData(x_true, v_true, nobspoints, std_noise_x, std_noise_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14374817e-03 9.23385948e-01 1.46755891e+00 1.86260211e+00\n",
      " 3.02332573e+00 3.45560727e+00 3.96767474e+00 4.17022005e+00\n",
      " 5.38816734e+00 7.20324493e+00] [1.14374817e-03 9.23385948e-01 1.46755891e+00 1.86260211e+00\n",
      " 3.02332573e+00 3.45560727e+00 3.96767474e+00 4.17022005e+00\n",
      " 5.38816734e+00 7.20324493e+00]\n"
     ]
    }
   ],
   "source": [
    "print(t_obs_init, t_obs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xleap, vleap, gradleap, dtleap, timeleap = leapfrog(position_value, momentum_value, t_obs_init, potential_and_grad_py, s_size, k=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evolve(params, t):\n",
    "    position_eval, momentum_eval, k, grad_eval, potential_eval, t_previous, x_eval, v_eval = params\n",
    "    print(t, t_previous)\n",
    "    deltat = t - t_previous\n",
    "    print(deltat)\n",
    "    new_p_eval, new_m_eval, new_p_eval, new_g_eval, new_x_eval, new_v_eval, new_time_step_eval = session.run(\n",
    "      [position_model, momentum_model, potential_model, grad_model, x_model, v_model, time_on_step_model],\n",
    "      feed_dict = {position: position_eval, momentum: momentum_eval, k: k, dt: deltat})#, grad:grad_val})\n",
    "    new_t_previous = t_previous + new_time_step_eval\n",
    "\n",
    "    params = [new_p_eval, new_m_eval, k, new_g_eval, new_p_eval, new_t_previous, new_x_val, new_v_val]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.14374817e-03, 9.23385948e-01, 1.46755891e+00, 1.86260211e+00,\n",
       "       3.02332573e+00, 3.45560727e+00, 3.96767474e+00, 4.17022005e+00,\n",
       "       5.38816734e+00, 7.20324493e+00])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_obs_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14374817e-03 9.23385948e-01 1.46755891e+00 1.86260211e+00\n",
      " 3.02332573e+00 3.45560727e+00 3.96767474e+00 4.17022005e+00\n",
      " 5.38816734e+00 7.20324493e+00]\n",
      "Tensor(\"scan/while/TensorArrayReadV3:0\", shape=(), dtype=float64) Tensor(\"scan/while/Identity_7:0\", shape=(), dtype=float64)\n",
      "Tensor(\"scan/while/sub:0\", shape=(), dtype=float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"scan/while/Identity_2:0\", shape=(), dtype=float64) which was passed to the feed with key <tf.Variable 'position:0' shape=() dtype=float64_ref>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-123c1c668d14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_obs_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mposition_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_previous_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Plot positions and momenta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(fn, elems, initializer, parallel_iterations, back_prop, swap_memory, infer_shape, reverse, name)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3230\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3231\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3232\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2950\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2951\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2952\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2953\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2885\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2886\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3200\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3201\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, a_flat, tas)\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0mpacked_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mpacked_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m       \u001b[0ma_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_elems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m       nest.assert_same_structure(\n\u001b[1;32m    664\u001b[0m           elems if initializer is None else initializer, a_out)\n",
      "\u001b[0;32m<ipython-input-48-6a7b0f0146b5>\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(params, t)\u001b[0m\n\u001b[1;32m      6\u001b[0m     new_p_eval, new_m_eval, new_p_eval, new_g_eval, new_x_eval, new_v_eval, new_time_step_eval = session.run(\n\u001b[1;32m      7\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0mposition_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_on_step_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       feed_dict = {position: position_eval, momentum: momentum_eval, k: k, dt: deltat})#, grad:grad_val})\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnew_t_previous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_previous\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_time_step_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                             \u001b[0;34m'For reference, the tensor object was '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' which was passed to the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                             'feed with key ' + str(feed) + '.')\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m           \u001b[0msubfeed_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"scan/while/Identity_2:0\", shape=(), dtype=float64) which was passed to the feed with key <tf.Variable 'position:0' shape=() dtype=float64_ref>."
     ]
    }
   ],
   "source": [
    "def potential_and_grad(position, k=np.float64(0.0)):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * tf.multiply(k,tf.square(position)), tf.multiply(k,position)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "#create placeholders for initial position and momentum, spring constant, and obs times to define model\n",
    "#there are what the feed dict will expect as inputs\n",
    "position = tf.get_variable(\"position\", dtype=tf.float64, initializer=tf.constant(position_value))\n",
    "momentum = tf.get_variable(\"momentum\", dtype=np.float64, initializer=tf.constant(momentum_value))\n",
    "k        = tf.get_variable(\"k\"         , dtype=np.float64, initializer=tf.constant(k_val))\n",
    "t_obs    = tf.get_variable(\"t_obs\"     , dtype=np.float64, initializer=tf.constant(t_obs_init))    \n",
    "    \n",
    "dt       = tf.get_variable(\"dt\"        , dtype=np.float64, initializer=tf.constant(np.float64(0.0)))\n",
    "#dt = tf.placeholder(np.float64, name='dt')\n",
    "step_size = tf.constant(0.01, dtype=np.float64) #tf.placeholder(np.float32, name='step_size')\n",
    "t_previous = tf.get_variable('tprevious', dtype=tf.float64, initializer = tf.constant(np.float64(0.0)))\n",
    "x         = tf.get_variable(\"x\",         dtype=tf.float64, initializer = tf.constant(np.float64(0.0)))\n",
    "v         = tf.get_variable(\"v\",         dtype=tf.float64, initializer = tf.constant(np.float64(0.0)))\n",
    "\n",
    "\n",
    "#new_ means model which you generated with placeholders, _val means instantiated value where you feed in param values\n",
    "\n",
    "#define potential\n",
    "\n",
    "potential_model, grad_model = potential_and_grad(position, k=k)\n",
    "\n",
    "#define model, leapfrog_integrator is from hmc tensorflow stuff\n",
    "\n",
    "position_model, momentum_model, potential_model, grad_model, x_model, v_model, time_on_step_model = tflf.leapfrog_integrator(\n",
    "    step_size, dt, position, momentum, potential_and_grad, grad_model)\n",
    "\n",
    "#generate arrays to save values from model\n",
    "positions = np.zeros([nobspoints, n_shos])\n",
    "momenta   = np.zeros([nobspoints, n_shos])\n",
    "grad      = np.zeros([nobspoints, n_shos])\n",
    "potential = np.zeros([nobspoints, n_shos])\n",
    "dt_tf     = np.zeros([nobspoints, n_shos])\n",
    "time_step = np.zeros([nobspoints, n_shos])\n",
    "#start session\n",
    "\n",
    "with tf.Session() as session:\n",
    "    # This step is needed to set up the variables.\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # And compute the log likelihood.\n",
    "    #print(\"The log likelihood computed using tensorflow: {0}\"\n",
    "    #      .format(session.run(log_like)))\n",
    "\n",
    "    #calculate potential and gradient at these random positions \n",
    "    potential_eval, grad_eval = session.run([potential_model, grad_model],\n",
    "                                 feed_dict={position: position_value, k: k_val})\n",
    "\n",
    "\n",
    "    #run model on random initial positions and momenta\n",
    "    #t_previous = 0.0\n",
    "    #for i, t in enumerate(t_obs_init):\n",
    "        #print(t, t_previous)\n",
    "        #deltat = np.float64(t - t_previous)\n",
    "        #print(deltat)\n",
    "        #position_val, momentum_val, potential_val, grad_val, x_val, v_val, dt_tiny_val, time_step_val = session.run(\n",
    "      #[new_position, new_momentum, new_potential, new_grad, x, v, dt_tiny_m, time_on_step],\n",
    "      #feed_dict = {position_0: position_val, momentum_0: momentum_val, \n",
    "       #        k: k_val, dt: deltat})#, grad:grad_val})\n",
    "        #positions[i] = x_val\n",
    "        #momenta[i] = v_val\n",
    "        #grad[i] = grad_val\n",
    "        #potential[i] = potential_val\n",
    "        #t_previous = t_previous + time_step_val\n",
    "        #dt_tf[i] = dt_tiny_val\n",
    "        #time_step[i] = t_previous\n",
    "    #dts = t_obs -\n",
    "    print(t_obs_true)\n",
    "    initializer = [position_value, momentum_value, k_val, grad_eval, potential_eval, t_previous_value, x_value, y_value]\n",
    "    tf.scan(evolve, t_obs, initializer= initializer)\n",
    "        \n",
    "# Plot positions and momenta \n",
    "#print(positions, momenta)\n",
    "fig, ax = plt.subplots(1,5, figsize=(20, 4))\n",
    "ax[0].plot(t_obs_init, xleap, 'o')\n",
    "ax[0].plot(t_obs_init, positions, 'o')\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('x')\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].plot(t_obs_init, vleap, 'o')\n",
    "ax[1].plot(t_obs_init, momenta, 'o')\n",
    "ax[2].plot(t_obs_init, gradleap, 'o')\n",
    "ax[2].plot(t_obs_init, grad, 'o')\n",
    "ax[3].plot(t_obs_init, dtleap, 'o', label='leap')\n",
    "ax[3].plot(t_obs_init, dt_tf, 'o', label='tf')\n",
    "ax[4].plot(t_obs_init, time_step, 'o')\n",
    "ax[4].plot(t_obs_init, timeleap, 'o')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_int = time_step.T + dt_tf.T\n",
    "print(t_obs_init, t_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot positions and momenta \n",
    "fig, ax = plt.subplots(1,5, figsize=(12, 4))\n",
    "ax[0].plot(t_obs_init, positions.T[0] - xleap.T, 'o')\n",
    "\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('x')\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].plot(t_obs_init, momenta.T[0] - vleap.T, 'o')\n",
    "ax[2].plot(t_obs_init, grad.T[0] - gradleap.T, 'o')\n",
    "ax[3].plot(t_obs_init, dt_tf.T[0] - dtleap.T, 'o')\n",
    "ax[4].plot(t_obs_init, time_step.T[0] - timeleap.T, 'o')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_step.T[0] - timeleap.T, dt_tf.T[0] - dtleap.T, 'o')\n",
    "plt.xlabel('Time Step TF - Time Step Leap')\n",
    "plt.ylabel('Small Step TF - Small Step Leap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tiny_t = t_obs_init % s_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step.T + dt_tf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0011437481734488664\n",
    "0.9222421995145291\n",
    "0.5441729604831524\n",
    "0.3950432056055786\n",
    "1.1607236125416887\n",
    "0.43228154411208\n",
    "0.5120674718762217\n",
    "0.20254530471904086\n",
    "1.2179472930078292\n",
    "1.8150775943880113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tiny_t - dt_tf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(time_step.T[0] - timeleap.T, positions.T[0] - xleap.T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dt_tf.T[0] - dtleap.T, positions.T[0] - xleap.T, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xleap.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License: See LICENSE\n",
    "# Fit a straight line, of the form y=m*x+b\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Your dataset.\n",
    "'''\n",
    "xs = np.linspace(0.0, 8.0, 8000000) # 8-million features\n",
    "ys = 0.3*xs-0.8+np.random.normal(scale=0.25, size=len(xs)) # 8-million labels\n",
    "\n",
    "'''\n",
    "Initial guesses, which will be refined by TensorFlow.\n",
    "'''\n",
    "m_initial = -0.5 # Initial guesses\n",
    "b_initial =  1.0\n",
    "\n",
    "'''\n",
    "Define free variables to be solved.\n",
    "'''\n",
    "m = tf.Variable(m_initial) # Parameters\n",
    "b = tf.Variable(b_initial)\n",
    "\n",
    "'''\n",
    "Define placeholders for big data.\n",
    "'''\n",
    "_BATCH = 8 # Use only eight points at a time.\n",
    "xs_placeholder = tf.placeholder(tf.float32, [_BATCH])\n",
    "ys_placeholder = tf.placeholder(tf.float32, [_BATCH]) \n",
    "\n",
    "'''\n",
    "Define the error between the data and the model as a tensor (distributed computing).\n",
    "'''\n",
    "ys_model = m*xs_placeholder+b # Tensorflow knows this is a vector operation\n",
    "total_error = tf.reduce_sum((ys_placeholder-ys_model)**2) # Sum up every item in the vector\n",
    "\n",
    "'''\n",
    "Once cost function is defined, create gradient descent optimizer.\n",
    "'''\n",
    "optimizer_operation = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(total_error) # Does one step\n",
    "\n",
    "'''\n",
    "Create operator for initialization.\n",
    "'''\n",
    "initializer_operation = tf.global_variables_initializer()\n",
    "\n",
    "'''\n",
    "All calculations are done in a session.\n",
    "'''\n",
    "with tf.Session() as session:\n",
    "\n",
    "\tsession.run(initializer_operation) # Call operator\n",
    "\n",
    "\t_EPOCHS = 10000 # Number of \"sweeps\" across data\n",
    "\tfor iteration in range(_EPOCHS):\n",
    "\t\trandom_indices = np.random.randint(len(xs), size=_BATCH) # Randomly sample the data\n",
    "\t\tfeed = {\n",
    "\t\t\txs_placeholder: xs[random_indices],\n",
    "\t\t\tys_placeholder: ys[random_indices]\n",
    "\t\t}\n",
    "\t\tsession.run(optimizer_operation, feed_dict=feed) # Call operator\n",
    "\n",
    "\tslope, intercept = session.run((m, b)) # Call \"m\" and \"b\", which are operators\n",
    "\tprint('Slope:', slope, 'Intercept:', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autograph.to_code(leapfrog))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
