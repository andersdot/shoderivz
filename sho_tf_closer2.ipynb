{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a simple harmonic oscillator and trying to infer the spring constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as so\n",
    "%matplotlib inline\n",
    "import numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad  \n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import autograph\n",
    "import test as tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define python functions first to compare with TF to debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genData(x, v, npoints, std_noise_x, std_noise_v):\n",
    "    noise_x = np.random.normal(0, std_noise_x, len(x))\n",
    "    noise_v = np.random.normal(0, std_noise_v, len(x))\n",
    "    return noise_x + x, noise_v + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_likelihood(theta, data, dt_model):\n",
    "    chi2 = 0\n",
    "    k, x0, v0, *t_obs = theta\n",
    "    x_obs, v_obs, sigma_x, sigma_v = data\n",
    "    x, v, _, _ = leapfrog(x0, v0, np.array(t_obs), potential_and_grad_py, dt_model, k=k)\n",
    "    chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "    chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "    return 0.5*chi2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def potential_and_grad_py(position, k=1.0):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * k * position**2, k*position\n",
    "\n",
    "def leap(position, momentum, grad, potential_and_grad, step_size, k=1.0):\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    position += step_size * momentum\n",
    "    potential, grad = potential_and_grad_py(position, k=k)\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    return position, momentum, potential, grad\n",
    "\n",
    "def leapfrog(x0, v0, t_obs, potential_and_grad_py, dt, k=np.float64(1.0)):\n",
    "    #function that takes initial conditions that takes us to the next position \n",
    "    x = [] \n",
    "    v = [] \n",
    "    t = [] \n",
    "    grads = []\n",
    "    time = []\n",
    "    \n",
    "    tprime = np.float64(0.0)\n",
    "    xprime = np.float64(x0)\n",
    "    vprime = np.float64(v0)\n",
    "    pot, grad = potential_and_grad_py(xprime, k=k)\n",
    "    for to in t_obs:\n",
    "\n",
    "        while tprime + dt < to:\n",
    "            xprime, vprime, pot, grad = leap(xprime, vprime, grad, potential_and_grad_py, dt, k=k)\n",
    "            tprime = tprime + dt    \n",
    "        dt_tiny = to - tprime\n",
    "        xsave, vsave, potsave, gradsave = leap(xprime, vprime, grad, potential_and_grad_py, dt_tiny, k=k)\n",
    "        tsave = tprime + dt_tiny\n",
    "        #print(xsave, vsave, tsave, potsave, gradsave)\n",
    "        x.append(xsave.copy())\n",
    "        v.append(vsave.copy())\n",
    "        t.append(tsave.copy())\n",
    "        grads.append(grad)\n",
    "        time.append(tprime)\n",
    "        #print(x, v)\n",
    "    return np.array(x), np.array(v), np.array(grads), np.array(time) #, np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some true values and initial guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0_true   = 100.\n",
    "v0_true   = 100.\n",
    "k_true    = 10.\n",
    "\n",
    "#define step size of each leap and number of shos\n",
    "s_size = np.float64(0.01)      #resolution of each leap\n",
    "n_shos = 1            #number of simple harmonic oscillators \n",
    "\n",
    "#set spring constant initial guess\n",
    "k = np.float64(10.0)\n",
    "\n",
    "#generate initial velocities and momenta guesses\n",
    "x0 = np.float64(10.0) #np.float64(np.random.randn(n_shos))\n",
    "v0 = np.float64(4.0) #np.float64(np.random.randn(n_shos))\n",
    "\n",
    "max_time  = np.float64(10.)\n",
    "nobspoints = 10\n",
    "#t_obs_true = np.linspace(0, max_time, nobspoints) \n",
    "t_obs_true = np.random.uniform(0, max_time, nobspoints)\n",
    "t_obs_true.sort()\n",
    "#generate initial times to model SHO, for now set equal to the true times\n",
    "t_obs = t_obs_true #np.random.uniform(0, max_time, nobspoints)#t_obs_init.sort()\n",
    "\n",
    "std_noise_x = 10.0\n",
    "std_noise_v = 10.0\n",
    "plot_xerr = np.zeros(nobspoints) + std_noise_x\n",
    "plot_yerr = np.zeros(nobspoints) + std_noise_v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data and model predictions using python implementation (which I trust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate true values and noisify them\n",
    "x_true, v_true, grad_true, time_steps_true = leapfrog(x0_true, v0_true, t_obs_true, potential_and_grad_py, s_size, k=k_true)\n",
    "x_obs, v_obs = genData(x_true, v_true, nobspoints, std_noise_x, std_noise_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate values using python leapfrog from initial guesses to compare with tf model\n",
    "xleap, vleap, gradleap, timeleap = leapfrog(x0,\n",
    "                                            v0,\n",
    "                                            t_obs,\n",
    "                                            potential_and_grad_py,\n",
    "                                            s_size,\n",
    "                                            k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2081.361073961145\n"
     ]
    }
   ],
   "source": [
    "#calculate log likelihood of initial guesses using python leapfrog model\n",
    "theta = [k, x0, v0] + t_obs.tolist()\n",
    "data = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "print(ln_likelihood(theta, data, s_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def evolve(params, t):\n",
    "    position_eval, momentum_eval, k, grad_eval, potential_eval, t_previous, x_eval, v_eval = params\n",
    "    print(t, t_previous)\n",
    "    deltat = t - t_previous\n",
    "    print(deltat)\n",
    "    new_p_eval, new_m_eval, new_p_eval, new_g_eval, new_x_eval, new_v_eval, new_time_step_eval = session.run(\n",
    "      [position_model, momentum_model, potential_model, grad_model, x_model, v_model, time_on_step_model],\n",
    "      feed_dict = {position: position_eval, momentum: momentum_eval, k: k, dt: deltat})#, grad:grad_val})\n",
    "    new_t_previous = t_previous + new_time_step_eval\n",
    "\n",
    "    params = [new_p_eval, new_m_eval, k, new_g_eval, new_p_eval, new_t_previous, new_x_val, new_v_val]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_log_like(x0, v0, k, t_obs, step_size, data):\n",
    "    chi2 = 0\n",
    "    x_obs, v_obs, sigma_x, sigma_v = data\n",
    "    x, v = tft.leapfrog(x0, v0, k, np.array(t_obs), step_size)\n",
    "    chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "    chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "    return 0.5*tf.reduce_sum(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define log likelihood model\n",
    "#ll = tf_log_like(x, v, x_obs_tf, v_obs_tf, std_noise_x_tf, std_noise_v_tf)\n",
    "tf.reset_default_graph()\n",
    "data = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "ll = tf_log_like(x0, v0, k, t_obs, s_size, data)\n",
    "\n",
    "#define gradients \n",
    "gradients = tf.gradients(ll, [x0, v0, k, t_obs]) #, current_v, k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TensorArray integrate/leapfrog/TensorArray_1_0: Could not write to TensorArray index 0 because it has already been written to.\n\t [[Node: integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3/Enter, integrate/leapfrog/tobs_loop/Identity_9, integrate/leapfrog/tobs_loop/leapfrog_to_obs/leap_frog_step/sub_1, integrate/leapfrog/tobs_loop/Switch_1:1)]]\n\nCaused by op 'integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-1360031e81ec>\", line 5, in <module>\n    ll = tf_log_like(x0, v0, k, t_obs, s_size, data)\n  File \"<ipython-input-46-b794957c5e2b>\", line 4, in tf_log_like\n    x, v = tft.leapfrog(x0, v0, k, np.array(t_obs), step_size)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 192, in leapfrog\n    step_size)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 154, in _leapfrog\n    name='tobs_loop')\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 132, in leap_to_tobs\n    v = v.write(i, vt)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 842, in write\n    return self._implementation.write(index, value, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 276, in write\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 7431, in tensor_array_write_v3\n    flow_in=flow_in, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): TensorArray integrate/leapfrog/TensorArray_1_0: Could not write to TensorArray index 0 because it has already been written to.\n\t [[Node: integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3/Enter, integrate/leapfrog/tobs_loop/Identity_9, integrate/leapfrog/tobs_loop/leapfrog_to_obs/leap_frog_step/sub_1, integrate/leapfrog/tobs_loop/Switch_1:1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TensorArray integrate/leapfrog/TensorArray_1_0: Could not write to TensorArray index 0 because it has already been written to.\n\t [[Node: integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3/Enter, integrate/leapfrog/tobs_loop/Identity_9, integrate/leapfrog/tobs_loop/leapfrog_to_obs/leap_frog_step/sub_1, integrate/leapfrog/tobs_loop/Switch_1:1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-b89a7a5199cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TensorArray integrate/leapfrog/TensorArray_1_0: Could not write to TensorArray index 0 because it has already been written to.\n\t [[Node: integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3/Enter, integrate/leapfrog/tobs_loop/Identity_9, integrate/leapfrog/tobs_loop/leapfrog_to_obs/leap_frog_step/sub_1, integrate/leapfrog/tobs_loop/Switch_1:1)]]\n\nCaused by op 'integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3', defined at:\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-47-1360031e81ec>\", line 5, in <module>\n    ll = tf_log_like(x0, v0, k, t_obs, s_size, data)\n  File \"<ipython-input-46-b794957c5e2b>\", line 4, in tf_log_like\n    x, v = tft.leapfrog(x0, v0, k, np.array(t_obs), step_size)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 192, in leapfrog\n    step_size)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 154, in _leapfrog\n    name='tobs_loop')\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\n    return_same_structure)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/Users/landerson/ahw2018/shoderivz/test.py\", line 132, in leap_to_tobs\n    v = v.write(i, vt)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 842, in write\n    return self._implementation.write(index, value, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 276, in write\n    name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 7431, in tensor_array_write_v3\n    flow_in=flow_in, name=name)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): TensorArray integrate/leapfrog/TensorArray_1_0: Could not write to TensorArray index 0 because it has already been written to.\n\t [[Node: integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](integrate/leapfrog/tobs_loop/leapfrog_to_obs/TensorArrayWrite_1/TensorArrayWriteV3/Enter, integrate/leapfrog/tobs_loop/Identity_9, integrate/leapfrog/tobs_loop/leapfrog_to_obs/leap_frog_step/sub_1, integrate/leapfrog/tobs_loop/Switch_1:1)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#=============================================================\n",
    "#=======  SETTING UP VARIABLES ===============================\n",
    "#=============================================================\n",
    "\n",
    "#the time resolution of the integrator\n",
    "step_size = tf.constant(s_size, dtype=np.float64, name='step_size') #tf.placeholder(np.float32, name='step_size')\n",
    "i         = tf.constant(np.float64(0.0), name='i')\n",
    "\n",
    "#turn fake data into tensorflow tensors \n",
    "x_obs_tf = tf.constant(x_obs, dtype=np.float64)\n",
    "v_obs_tf = tf.constant(v_obs, dtype=np.float64)\n",
    "std_noise_x_tf = tf.constant(std_noise_x, dtype=np.float64)\n",
    "std_noise_v_tf = tf.constant(std_noise_v, dtype=np.float64)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Main\"):\n",
    "\n",
    "    #create placeholders for initial position and momentum, spring constant, and obs times to define model\n",
    "    #these are the model parameters the optimize will find\n",
    "    current_x    = tf.TensorArray(tf.constant(current_x_value), name = \"current_x\", dtype=tf.float64)\n",
    "    current_v    = tf.TensorArray(tf.constant(current_v_value), name = \"current_v\", dtype=np.float64)\n",
    "    current_grad = tf.TensorArray(tf.constant(np.float64(0.0)), name = \"current_grad\", dtype=np.float64)\n",
    "    \n",
    "    x0           = tf.Variable(tf.constant(current_x_value), name = \"current_x\", dtype=tf.float64)\n",
    "    v0           = tf.Variable(tf.constant(current_v_value), name = \"current_v\", dtype=np.float64)\n",
    "    k            = tf.Variable(tf.constant(current_k_value), name = \"k\"        , dtype=np.float64)\n",
    "    t_obs        = tf.Variable(tf.constant(current_t_obs_values), name = \"t_obs\"   , dtype=np.float64)    \n",
    "\n",
    "    #the time of the previous observation to help us calculate dt\n",
    "    t_previous = tf.TensoryArray(tf.constant(np.float64(0.0)), name = 't_previous', dtype=tf.float64)\n",
    "    t_current  = tf.Variable(tf.constant(np.float64(1.0)), name = 't_current',  dtype=tf.float64)\n",
    "    #the time between the last observation time and the next\n",
    "    #so how long the current iteration should integrate to get to the next observation\n",
    "    #I'm a bit confused about when to use a placeholder and when to use a variable\n",
    "    #this is something I will always feed into the model and will change with each iteration\n",
    "    dt       = tf.TensoryArray(tf.constant(np.float64(1.0)), name = \"dt\"        , dtype=np.float64)\n",
    "\n",
    "\n",
    "    #the modeled observed positions and velocities compare with the actual observed positions and velocities for the loss function \n",
    "    x         = tf.TensorArray(tf.zeros(nobspoints, dtype=np.float64), name = \"x\", dtype=tf.float64)\n",
    "    v         = tf.TensorArray(tf.zeros(nobspoints, dtype=np.float64), name = \"v\", dtype=tf.float64)\n",
    "    nobs      = tf.Variable(tf.constant(nobspoints), name='nobs')\n",
    "\n",
    "#generate arrays to save values from model for debugging purposes \n",
    "grads     = np.zeros([nobspoints, n_shos])\n",
    "time_step = np.zeros([nobspoints, n_shos])\n",
    "\n",
    "\n",
    "\n",
    "#=============================================================\n",
    "#=======  DEFINING MODELS ====================================\n",
    "#=============================================================\n",
    "\n",
    "with tf.variable_scope('Main', reuse=tf.AUTO_REUSE):\n",
    "\n",
    "    #define potential model\n",
    "    potential_model, grad_model = potential_and_grad(current_x, k=k)\n",
    "\n",
    "    #define model, leapfrog_integrator is from hmc tensorflow stuff\n",
    "    model_leap = tflf.leapfrog_integrator(step_size, dt, \n",
    "                                      current_x, current_v, \n",
    "                                      potential_and_grad, \n",
    "                                      current_grad, t_previous, k=k)\n",
    "\n",
    "    #define log likelihood model\n",
    "    #ll = tf_log_like(x, v, x_obs_tf, v_obs_tf, std_noise_x_tf, std_noise_v_tf)\n",
    "    ll = tf_log_like(x0, v0, k, t_obs, x_obs_tf, v_obs_tf, std_noise_x_tf, std_noise_v_tf)\n",
    "\n",
    "    #define gradients \n",
    "    gradients = tf.gradients(ll, [x0, v0]) #, current_v, k])\n",
    "\n",
    "#=============================================================\n",
    "#=======  RUN TENSORFLOW =====================================\n",
    "#=============================================================\n",
    "\n",
    "with tf.Session() as session:\n",
    "    with tf.variable_scope('Main', reuse=tf.AUTO_REUSE):  \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        print([v.name for v in tf.all_variables()])\n",
    "        # This step is needed to set up the variables.\n",
    "\n",
    "\n",
    "        print(\"The log likelihood computed using tensorflow: {0}\"\n",
    "              .format(session.run(ll)))\n",
    "        grad\n",
    "        #print(\"The gradients are: {0}\".format(session.run(gradients)))\n",
    "        \n",
    "        fig, ax = plt.subplots(1,4, figsize=(10, 2.5))\n",
    "        ax[0].plot(current_t_obs_values, session.run(x) - xleap, 'o')\n",
    "        #print(session.run(x))\n",
    "        ax[0].set_xlabel('t')\n",
    "        ax[0].set_ylabel('$\\Delta x$')\n",
    "        ax[1].set_xlabel('t')\n",
    "        ax[1].set_ylabel('$\\Delta y$')\n",
    "        ax[1].plot(current_t_obs_values, session.run(v) - vleap, 'o')\n",
    "        ax[2].set_xlabel('t')\n",
    "        ax[2].set_ylabel('$\\Delta \\Phi$')\n",
    "        ax[2].plot(current_t_obs_values, grads.T[0] - gradleap.T, 'o')\n",
    "        ax[3].set_xlabel('t')\n",
    "        ax[3].set_ylabel('$\\Delta t$')\n",
    "        ax[3].plot(current_t_obs_values, time_step.T[0] - timeleap.T, 'o')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        fig, ax = plt.subplots(1,4, figsize=(10, 2.5))\n",
    "        ax[0].plot(current_t_obs_values, xleap, 'o')\n",
    "        ax[0].plot(current_t_obs_values, session.run(x), 'o')\n",
    "        ax[0].set_xlabel('t')\n",
    "        ax[0].set_ylabel('x')\n",
    "        ax[1].set_xlabel('t')\n",
    "        ax[1].set_ylabel('y')\n",
    "        ax[1].plot(current_t_obs_values, vleap, 'o')\n",
    "        ax[1].plot(current_t_obs_values, session.run(v), 'o')\n",
    "        \n",
    "ax[2].set_xlabel('t')\n",
    "ax[2].set_ylabel('gradient of potential')\n",
    "ax[2].plot(current_t_obs_values, gradleap, 'o')\n",
    "ax[2].plot(current_t_obs_values, grads, 'o')\n",
    "ax[3].set_xlabel('t')\n",
    "ax[3].set_ylabel('time at step')\n",
    "ax[3].plot(current_t_obs_values, time_step, 'o')\n",
    "ax[3].plot(current_t_obs_values, timeleap, 'o')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xleap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def scoping(fn, scope1, scope2, vals):\n",
    "    with fn(scope1):\n",
    "        a = tf.Variable(vals[0], name='a')\n",
    "        b = tf.get_variable('b', initializer=vals[1])\n",
    "        c = tf.constant(vals[2], name='c')\n",
    "\n",
    "        with fn(scope2):\n",
    "            d = tf.add(a * b, c, name='res')\n",
    "\n",
    "        print('\\n  '.join([scope1, a.name, b.name, c.name, d.name]), '\\n')\n",
    "    return d\n",
    "\n",
    "d1 = scoping(tf.variable_scope, 'scope_vars', 'res', [1, 2, 3])\n",
    "d2 = scoping(tf.name_scope,     'scope_name', 'res', [1, 2, 3])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([d1, d2]))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License: See LICENSE\n",
    "# Fit a straight line, of the form y=m*x+b\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Your dataset.\n",
    "'''\n",
    "xs = np.linspace(0.0, 8.0, 8000000) # 8-million features\n",
    "ys = 0.3*xs-0.8+np.random.normal(scale=0.25, size=len(xs)) # 8-million labels\n",
    "\n",
    "'''\n",
    "Initial guesses, which will be refined by TensorFlow.\n",
    "'''\n",
    "m_initial = -0.5 # Initial guesses\n",
    "b_initial =  1.0\n",
    "\n",
    "'''\n",
    "Define free variables to be solved.\n",
    "'''\n",
    "m = tf.Variable(m_initial) # Parameters\n",
    "b = tf.Variable(b_initial)\n",
    "\n",
    "'''\n",
    "Define placeholders for big data.\n",
    "'''\n",
    "_BATCH = 8 # Use only eight points at a time.\n",
    "xs_placeholder = tf.placeholder(tf.float32, [_BATCH])\n",
    "ys_placeholder = tf.placeholder(tf.float32, [_BATCH]) \n",
    "\n",
    "'''\n",
    "Define the error between the data and the model as a tensor (distributed computing).\n",
    "'''\n",
    "ys_model = m*xs_placeholder+b # Tensorflow knows this is a vector operation\n",
    "total_error = tf.reduce_sum((ys_placeholder-ys_model)**2) # Sum up every item in the vector\n",
    "\n",
    "'''\n",
    "Once cost function is defined, create gradient descent optimizer.\n",
    "'''\n",
    "optimizer_operation = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(total_error) # Does one step\n",
    "\n",
    "'''\n",
    "Create operator for initialization.\n",
    "'''\n",
    "initializer_operation = tf.global_variables_initializer()\n",
    "\n",
    "'''\n",
    "All calculations are done in a session.\n",
    "'''\n",
    "with tf.Session() as session:\n",
    "\n",
    "\tsession.run(initializer_operation) # Call operator\n",
    "\n",
    "\t_EPOCHS = 10000 # Number of \"sweeps\" across data\n",
    "\tfor iteration in range(_EPOCHS):\n",
    "\t\trandom_indices = np.random.randint(len(xs), size=_BATCH) # Randomly sample the data\n",
    "\t\tfeed = {\n",
    "\t\t\txs_placeholder: xs[random_indices],\n",
    "\t\t\tys_placeholder: ys[random_indices]\n",
    "\t\t}\n",
    "\t\tsession.run(optimizer_operation, feed_dict=feed) # Call operator\n",
    "\n",
    "\tslope, intercept = session.run((m, b)) # Call \"m\" and \"b\", which are operators\n",
    "\tprint('Slope:', slope, 'Intercept:', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autograph.to_code(leapfrog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        #calculate potential and gradient at initial position\n",
    "        #assign current_grad_value to current_grad model \n",
    "        current_potential_value, current_grad_value = session.run([potential_model, grad_model])\n",
    "\n",
    "        tf.assign(current_grad, np.float64(current_grad_value))\n",
    "        #print('all obs times: ', session.run(t_obs))\n",
    "        for i in range(nobspoints):\n",
    "            t_current = t_obs[i]\n",
    "            deltat = t_current - t_previous\n",
    "            #print('current time: ', session.run(t_current))\n",
    "            session.run(tf.assign(dt, deltat))\n",
    "            new_x, new_v, new_grad, new_t, x_value, v_value = session.run(model_leap)\n",
    "            session.run(tf.assign(x[i], x_value))\n",
    "            session.run(tf.assign(v[i], v_value))\n",
    "            session.run(tf.assign(current_x, new_x))\n",
    "            session.run(tf.assign(current_v, new_v))\n",
    "            session.run(tf.assign(current_grad, new_grad))\n",
    "            session.run(tf.assign(t_previous, new_t + t_previous))\n",
    "            #print('current dt: ', session.run(dt))\n",
    "            time_step[i] = session.run(t_previous)\n",
    "            grads[i] = new_grad\n",
    "            #print('current x: ', session.run(current_x))\n",
    "            #print('current v: ', session.run(current_v))\n",
    "            #print('current grad: ', session.run(current_grad))\n",
    "        \"\"\"\n",
    "        #define loop over t_obs, inside loop assigns values to x, v\n",
    "        #with tf.name_scope(None, 'evolve'):\n",
    "            #print(nobspoints)\n",
    "            count = tf.scan(evolve, np.arange(nobspoints), \n",
    "                              initializer=(tf.constant(np.float64(0.0), dtype=np.float64), \n",
    "                                           tf.constant(np.float64(0.0), dtype=np.float64),\n",
    "                                           tf.constant(np.float64(0.0), dtype=np.float64),\n",
    "                                           tf.constant(np.float64(0.0), dtype=np.float64),\n",
    "                                           tf.constant(np.float64(0.0), dtype=np.float64),\n",
    "                                           tf.constant(np.float64(0.0), dtype=np.float64)))\n",
    "                                           #tf.constant(np.int32(0.0))])\n",
    "                                              #[tf.constant(np.int32(0.0))])\n",
    "            print(session.run(count))\n",
    "        #loop = tf.map_fn(evolve, iteration) #, initializer=tf.constant(np.float64(0.0)))\n",
    "\n",
    "        #session.run(loop)\n",
    "        with tf.variable_scope('Main', reuse=tf.AUTO_REUSE):\n",
    "        \"\"\"\n",
    "def counter_fn(counter):  # pylint: disable=unused-argument\n",
    "    return counter  < 10\n",
    "\n",
    "def evolve(params, i):\n",
    "    print(i)\n",
    "    _, _, _, t_previous, _, _ = params\n",
    "    with tf.variable_scope('Main', reuse=tf.AUTO_REUSE):\n",
    "        tcurrent = tf.get_variable(\"t_obs\", [1], dtype=np.float64)[i]\n",
    "        dt = tcurrent - t_previous \n",
    "        new_x, new_v, new_grad, new_t, x_value, v_value = model_leap\n",
    "\n",
    "    return new_x, new_v, new_grad, new_t, x_value, v_value\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
