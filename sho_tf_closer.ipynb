{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a simple harmonic oscillator and trying to infer the spring constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as so\n",
    "%matplotlib inline\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad  \n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import autograph\n",
    "import tfleapfrog_copy2 as tflf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define python functions first to compare with TF to debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genData(x, v, npoints, std_noise_x, std_noise_v):\n",
    "    noise_x = np.random.normal(0, std_noise_x, len(x))\n",
    "    noise_v = np.random.normal(0, std_noise_v, len(x))\n",
    "    return noise_x + x, noise_v + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ln_likelihood(theta, data, dt_model):\n",
    "    chi2 = 0\n",
    "    k, x0, v0, *t_obs = theta\n",
    "    x_obs, v_obs, sigma_x, sigma_v = data\n",
    "    x, v, _, _ = leapfrog(x0, v0, np.array(t_obs), potential_and_grad_py, dt_model, k=k)\n",
    "    chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "    chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "    return 0.5*chi2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def potential_and_grad_py(position, k=1.0):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * k * position**2, k*position\n",
    "\n",
    "def leap(position, momentum, grad, potential_and_grad, step_size, k=1.0):\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    position += step_size * momentum\n",
    "    potential, grad = potential_and_grad_py(position, k=k)\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    return position, momentum, potential, grad\n",
    "\n",
    "def leapfrog(x0, v0, t_obs, potential_and_grad_py, dt, k=np.float64(1.0)):\n",
    "    #function that takes initial conditions that takes us to the next position \n",
    "    x = [] \n",
    "    v = [] \n",
    "    t = [] \n",
    "    grads = []\n",
    "    time = []\n",
    "    \n",
    "    tprime = np.float64(0.0)\n",
    "    xprime = np.float64(x0)\n",
    "    vprime = np.float64(v0)\n",
    "    pot, grad = potential_and_grad_py(xprime, k=k)\n",
    "    for to in t_obs:\n",
    "\n",
    "        while tprime + dt < to:\n",
    "            xprime, vprime, pot, grad = leap(xprime, vprime, grad, potential_and_grad_py, dt, k=k)\n",
    "            tprime = tprime + dt    \n",
    "        dt_tiny = to - tprime\n",
    "        xsave, vsave, potsave, gradsave = leap(xprime, vprime, grad, potential_and_grad_py, dt_tiny, k=k)\n",
    "        tsave = tprime + dt_tiny\n",
    "        #print(xsave, vsave, tsave, potsave, gradsave)\n",
    "        x.append(xsave.copy())\n",
    "        v.append(vsave.copy())\n",
    "        t.append(tsave.copy())\n",
    "        grads.append(grad)\n",
    "        time.append(tprime)\n",
    "        #print(x, v)\n",
    "    return np.array(x), np.array(v), np.array(grads), np.array(time) #, np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some true values and initial guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0_true   = 100.\n",
    "v0_true   = 100.\n",
    "k_true    = 10.\n",
    "\n",
    "#define step size of each leap and number of shos\n",
    "s_size = np.float64(0.01)      #resolution of each leap\n",
    "n_shos = 1            #number of simple harmonic oscillators \n",
    "\n",
    "#set spring constant initial guess\n",
    "current_k_value = np.float64(10.0)\n",
    "\n",
    "#generate initial velocities and momenta guesses\n",
    "current_x_value = np.float64(10.0) #np.float64(np.random.randn(n_shos))\n",
    "current_v_value = np.float64(4.0) #np.float64(np.random.randn(n_shos))\n",
    "\n",
    "max_time  = np.float64(10.)\n",
    "nobspoints = 10\n",
    "#t_obs_true = np.linspace(0, max_time, nobspoints) \n",
    "t_obs_true = np.random.uniform(0, max_time, nobspoints)\n",
    "t_obs_true.sort()\n",
    "#generate initial times to model SHO, for now set equal to the true times\n",
    "current_t_obs_values = t_obs_true #np.random.uniform(0, max_time, nobspoints)#t_obs_init.sort()\n",
    "\n",
    "std_noise_x = 10.0\n",
    "std_noise_v = 10.0\n",
    "plot_xerr = np.zeros(nobspoints) + std_noise_x\n",
    "plot_yerr = np.zeros(nobspoints) + std_noise_v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data and model predictions using python implementation (which I trust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate true values and noisify them\n",
    "x_true, v_true, grad_true, time_steps_true = leapfrog(x0_true, v0_true, t_obs_true, potential_and_grad_py, s_size, k=k_true)\n",
    "x_obs, v_obs = genData(x_true, v_true, nobspoints, std_noise_x, std_noise_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate values using python leapfrog from initial guesses to compare with tf model\n",
    "xleap, vleap, gradleap, timeleap = leapfrog(current_x_value,\n",
    "                                            current_v_value,\n",
    "                                            current_t_obs_values,\n",
    "                                            potential_and_grad_py,\n",
    "                                            s_size,\n",
    "                                            k=current_k_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2081.361073961145\n"
     ]
    }
   ],
   "source": [
    "#calculate log likelihood of initial guesses using python leapfrog model\n",
    "theta = [current_k_value, current_x_value, current_v_value] +  current_t_obs_values.tolist()\n",
    "data = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "print(ln_likelihood(theta, data, s_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def evolve(params, t):\n",
    "    position_eval, momentum_eval, k, grad_eval, potential_eval, t_previous, x_eval, v_eval = params\n",
    "    print(t, t_previous)\n",
    "    deltat = t - t_previous\n",
    "    print(deltat)\n",
    "    new_p_eval, new_m_eval, new_p_eval, new_g_eval, new_x_eval, new_v_eval, new_time_step_eval = session.run(\n",
    "      [position_model, momentum_model, potential_model, grad_model, x_model, v_model, time_on_step_model],\n",
    "      feed_dict = {position: position_eval, momentum: momentum_eval, k: k, dt: deltat})#, grad:grad_val})\n",
    "    new_t_previous = t_previous + new_time_step_eval\n",
    "\n",
    "    params = [new_p_eval, new_m_eval, k, new_g_eval, new_p_eval, new_t_previous, new_x_val, new_v_val]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operation 'map/while/Assign' has been marked as not fetchable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-38bcece0219e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m#define loop over t_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnobspoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, initializer=tf.constant(np.float64(0.0)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    460\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3230\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3231\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3232\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2950\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2951\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2952\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2953\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2885\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2886\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3200\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3201\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    446\u001b[0m       \"\"\"\n\u001b[1;32m    447\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-38bcece0219e>\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#dt = t_obs[i] - t_previous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_previous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#session.run(tf.assign(dt, t_obs[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#print(t_obs[i], t_previous)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1085\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m       raise ValueError(\n\u001b[0;32m--> 453\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'map/while/Assign' has been marked as not fetchable."
     ]
    }
   ],
   "source": [
    "def potential_and_grad(position, k=np.float64(1.0)):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * k * tf.square(position), k * position\n",
    "\n",
    "def tf_log_like(modelx, modelv, obsx, obsv, sigmax, sigmav):\n",
    "\n",
    "    chi2 = np.float64(0.0)\n",
    "    #ideally I'd like to feed in model parameters and calculate model x, v here\n",
    "    chi2 += (modelv - obsv)**2 / sigmav**2 + 2*tf.log(sigmav)\n",
    "    chi2 += (modelx - obsx)**2 / sigmax**2 + 2*tf.log(sigmax)\n",
    "    return -0.5*tf.reduce_sum(chi2)\n",
    "\n",
    "def evolve(i):\n",
    "    session.run(dt.assign(t_obs[i] - t_previous))\n",
    "    x_value, v_value = session.run(model_leap)\n",
    "    session.run(tf.assign(x[i], x_value))\n",
    "    session.run(tf.assign(v[i], v_value))\n",
    "    return i\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#=============================================================\n",
    "#=======  SETTING UP VARIABLES ===============================\n",
    "#=============================================================\n",
    "\n",
    "#create placeholders for initial position and momentum, spring constant, and obs times to define model\n",
    "#these are the model parameters the optimize will find\n",
    "current_x = tf.get_variable(\"position\", dtype=tf.float64, initializer=tf.constant(current_x_value))\n",
    "current_v = tf.get_variable(\"momentum\", dtype=np.float64, initializer=tf.constant(current_v_value))\n",
    "current_grad = tf.get_variable(\"grad\", dtype=np.float64, initializer=tf.constant(np.float64(0.0)))\n",
    "k         = tf.get_variable(\"k\"       , dtype=np.float64, initializer=tf.constant(current_k_value))\n",
    "t_obs     = tf.get_variable(\"t_obs\"   , dtype=np.float64, initializer=tf.constant(current_t_obs_values))    \n",
    "\n",
    "#the time of the previous observation to help us calculate dt\n",
    "t_previous = tf.get_variable('tprevious', dtype=tf.float64, initializer = tf.constant(np.float64(0.0)))\n",
    "\n",
    "#the time between the last observation time and the next\n",
    "#so how long the current iteration should integrate to get to the next observation\n",
    "#I'm a bit confused about when to use a placeholder and when to use a variable\n",
    "#this is something I will always feed into the model and will change with each iteration\n",
    "dt       = tf.get_variable(\"dt\"        , dtype=np.float64, initializer=tf.constant(np.float64(0.0)))\n",
    "\n",
    "#the time resolution of the integrator\n",
    "step_size = tf.constant(s_size, dtype=np.float64, name='step_size') #tf.placeholder(np.float32, name='step_size')\n",
    "i         = tf.constant(np.float64(0.0), name='i')\n",
    "\n",
    "#the modeled observed positions and velocities compare with the actual observed positions and velocities for the loss function \n",
    "x         = tf.get_variable(\"x\", dtype=tf.float64, initializer = tf.zeros(nobspoints, dtype=np.float64))\n",
    "v         = tf.get_variable(\"v\", dtype=tf.float64, initializer = tf.zeros(nobspoints, dtype=np.float64))\n",
    "\n",
    "#turn fake data into tensorflow tensors \n",
    "x_obs_tf = tf.constant(x_obs, dtype=np.float64)\n",
    "v_obs_tf = tf.constant(v_obs, dtype=np.float64)\n",
    "std_noise_x_tf = tf.constant(std_noise_x, dtype=np.float64)\n",
    "std_noise_v_tf = tf.constant(std_noise_v, dtype=np.float64)\n",
    "\n",
    "#generate arrays to save values from model for debugging purposes \n",
    "#positions = np.zeros([nobspoints, n_shos])\n",
    "#velocities= np.zeros([nobspoints, n_shos])\n",
    "#grads     = np.zeros([nobspoints, n_shos])\n",
    "#potential = np.zeros([nobspoints, n_shos])\n",
    "#dt_tf     = np.zeros([nobspoints, n_shos])\n",
    "#time_step = np.zeros([nobspoints, n_shos])\n",
    "#start session\n",
    "\n",
    "\n",
    "#=============================================================\n",
    "#=======  DEFINING MODELS ====================================\n",
    "#=============================================================\n",
    "\n",
    "#define potential model\n",
    "potential_model, grad_model = potential_and_grad(current_x, k=k)\n",
    "\n",
    "#define model, leapfrog_integrator is from hmc tensorflow stuff\n",
    "model_leap = tflf.leapfrog_integrator(step_size, dt, \n",
    "                                      current_x, current_v, \n",
    "                                      potential_and_grad, \n",
    "                                      current_grad, t_previous, k=k)\n",
    "\n",
    "#define log likelihood model\n",
    "ll = tf_log_like(x, v, x_obs_tf, v_obs_tf, std_noise_x_tf, std_noise_v_tf)\n",
    "\n",
    "#define gradients \n",
    "grad = tf.gradients(ll, [x, v])\n",
    "\n",
    "#=============================================================\n",
    "#=======  RUN TENSORFLOW =====================================\n",
    "#=============================================================\n",
    "\n",
    "with tf.Session() as session:\n",
    "    # This step is needed to set up the variables.\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #calculate potential and gradient at initial position\n",
    "    #assign current_grad_value to current_grad model \n",
    "    current_potential_value, current_grad_value = session.run([potential_model, grad_model])\n",
    "    current_grad.assign(current_grad_value)\n",
    "    \n",
    "    #define loop over t_obs, inside loop assigns values to x, v\n",
    "    iteration = np.arange(nobspoints)\n",
    "    loop = tf.map_fn(evolve, iteration) #, initializer=tf.constant(np.float64(0.0)))\n",
    "\n",
    "    session.run(loop)\n",
    "    print(session.run(x))\n",
    "    print(session.run(v))\n",
    "    print(\"The log likelihood computed using tensorflow: {0}\"\n",
    "          .format(session.run(ll)))\n",
    "    #print(session.run(grad))\n",
    "    # Plot positions and momenta \n",
    "    #print(positions, momenta)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10, 4))\n",
    "    ax[0].plot(current_t_obs_values, xleap, 'o')\n",
    "    ax[0].plot(current_t_obs_values, session.run(x), 'o')\n",
    "    ax[0].set_xlabel('t')\n",
    "    ax[0].set_ylabel('x')\n",
    "    ax[1].set_xlabel('t')\n",
    "    ax[1].set_ylabel('y')\n",
    "    ax[1].plot(current_t_obs_values, vleap, 'o')\n",
    "    ax[1].plot(current_t_obs_values, session.run(v), 'o')\n",
    "#ax[2].set_xlabel('t')\n",
    "#ax[2].set_ylabel('gradient of potential')\n",
    "#ax[2].plot(current_t_obs_values, gradleap, 'o')\n",
    "#ax[2].plot(current_t_obs_values, grads, 'o')\n",
    "#ax[3].set_xlabel('t')\n",
    "#ax[3].set_ylabel('time at step')\n",
    "#ax[3].plot(current_t_obs_values, time_step, 'o')\n",
    "#ax[3].plot(current_t_obs_values, timeleap, 'o')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot positions and momenta \n",
    "fig, ax = plt.subplots(1,4, figsize=(10, 3))\n",
    "ax[0].plot(current_t_obs_values, positions.T[0] - xleap.T, 'o')\n",
    "\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('$\\Delta x$')\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('$\\Delta y$')\n",
    "ax[1].plot(current_t_obs_values, velocities.T[0] - vleap.T, 'o')\n",
    "ax[2].set_xlabel('t')\n",
    "ax[2].set_ylabel('$\\Delta \\Phi$')\n",
    "ax[2].plot(current_t_obs_values, grads.T[0] - gradleap.T, 'o')\n",
    "ax[3].set_xlabel('t')\n",
    "ax[3].set_ylabel('$\\Delta t$')\n",
    "ax[3].plot(current_t_obs_values, time_step.T[0] - timeleap.T, 'o')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(time_step.T[0] - timeleap.T, positions.T[0] - xleap.T, 'o')\n",
    "plt.xlabel('$\\Delta T$')\n",
    "plt.ylabel('$\\Delta X$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def scoping(fn, scope1, scope2, vals):\n",
    "    with fn(scope1):\n",
    "        a = tf.Variable(vals[0], name='a')\n",
    "        b = tf.get_variable('b', initializer=vals[1])\n",
    "        c = tf.constant(vals[2], name='c')\n",
    "\n",
    "        with fn(scope2):\n",
    "            d = tf.add(a * b, c, name='res')\n",
    "\n",
    "        print('\\n  '.join([scope1, a.name, b.name, c.name, d.name]), '\\n')\n",
    "    return d\n",
    "\n",
    "d1 = scoping(tf.variable_scope, 'scope_vars', 'res', [1, 2, 3])\n",
    "d2 = scoping(tf.name_scope,     'scope_name', 'res', [1, 2, 3])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([d1, d2]))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License: See LICENSE\n",
    "# Fit a straight line, of the form y=m*x+b\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Your dataset.\n",
    "'''\n",
    "xs = np.linspace(0.0, 8.0, 8000000) # 8-million features\n",
    "ys = 0.3*xs-0.8+np.random.normal(scale=0.25, size=len(xs)) # 8-million labels\n",
    "\n",
    "'''\n",
    "Initial guesses, which will be refined by TensorFlow.\n",
    "'''\n",
    "m_initial = -0.5 # Initial guesses\n",
    "b_initial =  1.0\n",
    "\n",
    "'''\n",
    "Define free variables to be solved.\n",
    "'''\n",
    "m = tf.Variable(m_initial) # Parameters\n",
    "b = tf.Variable(b_initial)\n",
    "\n",
    "'''\n",
    "Define placeholders for big data.\n",
    "'''\n",
    "_BATCH = 8 # Use only eight points at a time.\n",
    "xs_placeholder = tf.placeholder(tf.float32, [_BATCH])\n",
    "ys_placeholder = tf.placeholder(tf.float32, [_BATCH]) \n",
    "\n",
    "'''\n",
    "Define the error between the data and the model as a tensor (distributed computing).\n",
    "'''\n",
    "ys_model = m*xs_placeholder+b # Tensorflow knows this is a vector operation\n",
    "total_error = tf.reduce_sum((ys_placeholder-ys_model)**2) # Sum up every item in the vector\n",
    "\n",
    "'''\n",
    "Once cost function is defined, create gradient descent optimizer.\n",
    "'''\n",
    "optimizer_operation = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(total_error) # Does one step\n",
    "\n",
    "'''\n",
    "Create operator for initialization.\n",
    "'''\n",
    "initializer_operation = tf.global_variables_initializer()\n",
    "\n",
    "'''\n",
    "All calculations are done in a session.\n",
    "'''\n",
    "with tf.Session() as session:\n",
    "\n",
    "\tsession.run(initializer_operation) # Call operator\n",
    "\n",
    "\t_EPOCHS = 10000 # Number of \"sweeps\" across data\n",
    "\tfor iteration in range(_EPOCHS):\n",
    "\t\trandom_indices = np.random.randint(len(xs), size=_BATCH) # Randomly sample the data\n",
    "\t\tfeed = {\n",
    "\t\t\txs_placeholder: xs[random_indices],\n",
    "\t\t\tys_placeholder: ys[random_indices]\n",
    "\t\t}\n",
    "\t\tsession.run(optimizer_operation, feed_dict=feed) # Call operator\n",
    "\n",
    "\tslope, intercept = session.run((m, b)) # Call \"m\" and \"b\", which are operators\n",
    "\tprint('Slope:', slope, 'Intercept:', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(autograph.to_code(leapfrog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
