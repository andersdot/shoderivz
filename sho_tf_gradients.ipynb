{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating a simple harmonic oscillator and trying to infer the spring constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "import scipy.optimize as so\n",
    "%matplotlib inline\n",
    "import autograd.numpy as np # Thinly-wrapped numpy\n",
    "#import numpy as np  \n",
    "from autograd import grad  \n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import autograph\n",
    "import leapfrog as lf\n",
    "from tensorflow.python.ops import gradients_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define python functions first to compare with TF to debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genData(x, v, npoints, std_noise_x, std_noise_v):\n",
    "    noise_x = np.random.normal(0, std_noise_x, len(x))\n",
    "    noise_v = np.random.normal(0, std_noise_v, len(x))\n",
    "    return noise_x + x, noise_v + v\n",
    "\n",
    "def ln_likelihood(theta, data, dt_model):\n",
    "    chi2 = 0\n",
    "    k, x0, v0, *t_obs = theta\n",
    "    x_obs, v_obs, sigma_x, sigma_v = data\n",
    "    x, v, _, _ = leapfrog(x0, v0, np.array(t_obs), potential_and_grad_py, dt_model, k=k)\n",
    "    chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "    chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "    return 0.5*chi2.sum()\n",
    "\n",
    "def tf_log_like(x0, v0, k, t_obs, step_size, data, name='loglikelihood'):\n",
    "    with tf.name_scope(name):\n",
    "        chi2 = 0\n",
    "        x_obs, v_obs, sigma_x, sigma_v = data\n",
    "        x, v = lf.leapfrog(x0, v0, k, t_obs, step_size, name='leapfrog')\n",
    "        chi2 += -(v - v_obs)**2 / sigma_v**2 - 2*np.log(sigma_v)\n",
    "        chi2 += -(x - x_obs)**2 / sigma_x**2 - 2*np.log(sigma_x)\n",
    "        return 0.5*tf.reduce_sum(chi2)\n",
    "\n",
    "def nll_python(*args):\n",
    "    return -ln_likelihood(*args)\n",
    "\n",
    "def potential_and_grad_py(position, k=1.0):\n",
    "    #function that returns the potential and it's gradient at a given position\n",
    "    return 0.5 * k * position**2, k*position\n",
    "\n",
    "def leap(position, momentum, grad, potential_and_grad, step_size, k=1.0):\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    position += step_size * momentum\n",
    "    potential, grad = potential_and_grad_py(position, k=k)\n",
    "    momentum -= 0.5 * step_size * grad\n",
    "    return position, momentum, potential, grad\n",
    "\n",
    "def leapfrog(x0, v0, t_obs, potential_and_grad_py, dt, k=np.float64(1.0)):\n",
    "    #function that takes initial conditions that takes us to the next position \n",
    "    x = [] \n",
    "    v = [] \n",
    "    t = [] \n",
    "    grads = []\n",
    "    time = []\n",
    "    \n",
    "    tprime = 0.0\n",
    "    xprime = x0\n",
    "    vprime = v0\n",
    "\n",
    "    pot, grad = potential_and_grad_py(xprime, k=k)\n",
    "    for to in t_obs:\n",
    "\n",
    "        while tprime + dt < to:\n",
    "            xprime, vprime, pot, grad = leap(xprime, vprime, grad, potential_and_grad_py, dt, k=k)\n",
    "            tprime = tprime + dt    \n",
    "        dt_tiny = to - tprime\n",
    "        xsave, vsave, potsave, gradsave = leap(xprime, vprime, grad, potential_and_grad_py, dt_tiny, k=k)\n",
    "        tsave = tprime + dt_tiny\n",
    "        #print(xsave, vsave, tsave, potsave, gradsave)\n",
    "        x.append(xsave)\n",
    "        v.append(vsave)\n",
    "        t.append(tsave)\n",
    "        grads.append(grad)\n",
    "        time.append(tprime)\n",
    "        #print(x, v)\n",
    "    return np.array(x), np.array(v), np.array(grads), np.array(time) #, np.array(t)\n",
    "\n",
    "def finite_difference_grads(k_true, x0_true, \n",
    "                            v0_true, t_obs_true, \n",
    "                            epsilon):\n",
    "    grads = []\n",
    "    \n",
    "    k = k_true\n",
    "    x0 = x0_true\n",
    "    v0 = v0_true\n",
    "    t0 = t_obs_true\n",
    "    k = k_true + epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    kp = nll_python(p0_test, data, s_size)\n",
    "    k = k_true - epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    km = nll_python(p0_test, data, s_size)\n",
    "    k = k_true\n",
    "\n",
    "    grads.append((kp - km)/epsilon)\n",
    "\n",
    "\n",
    "    x0 = x0_true + epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    xp = nll_python(p0_test, data, s_size)\n",
    "    x0 = x0_true - epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    xm = nll_python(p0_test, data, s_size)\n",
    "    x0 = x0_true\n",
    "\n",
    "    grads.append((xp - xm)/epsilon)\n",
    "\n",
    "    v0 = v0_true + epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    vp = nll_python(p0_test, data, s_size)\n",
    "    v0 = v0_true - epsilon/2.\n",
    "    p0_test = [k, x0, v0] + (t0).tolist()\n",
    "    vm = nll_python(p0_test, data, s_size)\n",
    "    v0 = v0_true\n",
    "\n",
    "    grads.append((vp - vm)/epsilon)\n",
    "\n",
    "    for i, t in enumerate(t0):\n",
    "        t_obs_true[i] = t + epsilon/2.\n",
    "        p0_test = [k, x0, v0] + (t0).tolist()\n",
    "        tp = nll_python(p0_test, data, s_size)\n",
    "        t_obs_true[i] = t - epsilon/2.\n",
    "        p0_test = [k, x0, v0] + (t0).tolist()\n",
    "        tm = nll_python(p0_test, data, s_size)\n",
    "        t_obs_true[i] = t\n",
    "\n",
    "        grads.append((tp - tm)/epsilon)\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some true values and initial guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define true parameter values we will add noise to later\n",
    "x0_true   = np.float64(10.)\n",
    "v0_true   = np.float64(10.)\n",
    "k_true    = np.float64(3.)\n",
    "\n",
    "#define step size of each leap and number of shos\n",
    "s_size = np.float64(0.01)      #resolution of each leap\n",
    "n_shos = 1            #number of simple harmonic oscillators \n",
    "\n",
    "#define true observed times\n",
    "max_time  = np.float64(10.)\n",
    "nobspoints = 10\n",
    "t_obs_true = np.random.uniform(0, max_time, nobspoints)\n",
    "t_obs_true.sort()\n",
    "\n",
    "#define noise properties \n",
    "std_noise_x = 1.0\n",
    "std_noise_v = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data and model predictions using python implementation (which I trust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate true values and noisify them\n",
    "x_true, v_true, grad_true, time_steps_true = leapfrog(x0_true, v0_true, t_obs_true, potential_and_grad_py, s_size, k=k_true)\n",
    "x_obs, v_obs = genData(x_true, v_true, nobspoints, std_noise_x, std_noise_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data   = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "\n",
    "k_guess = k_true  + np.random.normal(0, k_true)\n",
    "x0_guess = x0_true + np.random.normal(0, std_noise_x)\n",
    "v0_guess = v0_true + np.random.normal(0, std_noise_v)\n",
    "t0_guess = t_obs_true #+ np.random.normal(0, 1., len(t_obs_true))\n",
    "t0_guess.sort()\n",
    "p0_guess = [k_guess, \n",
    "          x0_guess, \n",
    "          v0_guess] + (t0_guess).tolist()\n",
    "\n",
    "#for plotting purposes\n",
    "t_compare = np.linspace(0, max_time, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate log likelihood of python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate log likelihood of initial guesses using python leapfrog model\n",
    "theta = [k_guess, x0_guess, v0_guess] + t0_guess.tolist()\n",
    "data = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "python_loglikelihood = ln_likelihood(theta, data, s_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate autograd gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define autograd gradient function\n",
    "grad_ln_like = grad(nll_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads_autograd = grad_ln_like(p0_guess, data, s_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate finite difference gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.0001\n",
    "grads_finite_difference = finite_difference_grads(k_guess, x0_guess, v0_guess, t0_guess, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try with TensorFlow\n",
    "## Define Tensorflow variables and Tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define log likelihood model\n",
    "#ll = tf_log_like(x, v, x_obs_tf, v_obs_tf, std_noise_x_tf, std_noise_v_tf)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "data = [x_obs, v_obs, std_noise_x, std_noise_v]\n",
    "\n",
    "#turn initial parameter guesses into tensorflow tensors so tensorflow can take gradients of them\n",
    "\n",
    "x0_tf    = tf.Variable(tf.constant(x0_guess), name = \"x0\"   , dtype=np.float64)\n",
    "v0_tf    = tf.Variable(tf.constant(v0_guess), name = \"v0\"   , dtype=np.float64)\n",
    "k_tf     = tf.Variable(tf.constant(k_guess),  name = \"k\"    , dtype=np.float64)\n",
    "t_obs_tf = tf.Variable(tf.constant(t0_guess), name = \"t_obs\", dtype=np.float64)    \n",
    "\n",
    "#define tensorflow models\n",
    "#returns the modeled x and v values \n",
    "model = lf.leapfrog(x0_tf, v0_tf, k_tf, t_obs_tf, s_size, name='leapfrog')\n",
    "#returns the negative log likelihood of the parameters\n",
    "nll = -tf_log_like(x0_tf, v0_tf, k_tf, t_obs_tf, s_size, data, name='negativeloglike')\n",
    "#returns the likelihood of the parameters\n",
    "ll = tf_log_like(x0_tf, v0_tf, k_tf, t_obs_tf, s_size, data, name='loglikelihood')\n",
    "\n",
    "#returns the gradients of the negative log likelihood\n",
    "gradients = gradients_impl.gradients(nll, [k_tf, x0_tf, v0_tf, t_obs_tf]) #, current_v, k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Tensorflow models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "#initialize all variables that are defined\n",
    "session.run(tf.global_variables_initializer())\n",
    "#run model to get x, v for debugging purposes in plots below\n",
    "x, v = session.run(model)\n",
    "writer = tf.summary.FileWriter(\"/tmp/leapfrog/model\")\n",
    "writer.add_graph(session.graph)\n",
    "#compute likelihood of model parameters\n",
    "tensorflow_loglikelihood = session.run(ll)\n",
    "writer = tf.summary.FileWriter(\"/tmp/leapfrog/loglike\")\n",
    "writer.add_graph(session.graph)\n",
    "#compute the gradients of the negative log likelihood with respect to all the parameters \n",
    "grads_tensorflow = session.run(gradients)\n",
    "writer = tf.summary.FileWriter(\"/tmp/leapfrog/negloglike\")\n",
    "writer.add_graph(session.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now plot some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate values using python leapfrog from initial guesses to plot\n",
    "plot_t_obs_values = np.linspace(0, max_time, 1000)\n",
    "xleap_plot, vleap_plot, gradleap_plot, timeleap_plot = leapfrog(x0_guess,\n",
    "                                            v0_guess,\n",
    "                                            plot_t_obs_values,\n",
    "                                            potential_and_grad_py,\n",
    "                                            s_size,\n",
    "                                            k=k_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate values using python leapfrog from initial guesses to compare with tf model\n",
    "xleap, vleap, gradleap, timeleap = leapfrog(x0_guess,\n",
    "                                            v0_guess,\n",
    "                                            t0_guess,\n",
    "                                            potential_and_grad_py,\n",
    "                                            s_size,\n",
    "                                            k=k_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAC0CAYAAACqufbBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gRsZlaIE7CZWSFOwGZmhTgBm5kV8v8BBaEgBw+SjXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c288eebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACsCAYAAABFPHY3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXl0XFed5z+3Sirtq7XLUpVWy5Ji\nO7ZlO1YgSSdkw+2QDJwGGjpwYPCZAJ1uIA1MA0kPhGHw4WQg0007DRkITTcnkLitHhKckIUkzmLZ\n8hJJtlZLlixZiy3ZlrVX3fmj9GTtquUtJfl+ztGR9N6r935V9Xvf97v3/u79CSklCoVCoTAfm9UG\nKBQKxfWKEmCFQqGwCCXACoVCYRFKgBUKhcIilAArFAqFRSgBVigUCotQAqxQKBQWoQRYoVAoLEIJ\nsEKhUFhEmNUG6EFKSop0uVxWm6EwgKNHj/ZLKVOttsMolO+uTnz121UhwC6XiyNHjlhthsIAhBDt\nVttgJMp3Vye++q3qglAoFAqLWBUR8EqnumofOTV7SZN99IpUOjY/QsXuPVabpVCsCFby/XNdRMDj\n4+PU1dUxOTlptSnzqK7aR/nRb5FBHxdHPIwO9lB+9FtUV+2z2rRFaWxs5PLly1aboTCYoaEhTp8+\nTSivmFhdtY/E174JQz3YBGTQF/L3z0xWvQAPDAywZcsWysvLueWWW7h69arVJs0ip2YvUWKcPzRP\nkvPEEHk/HuLHh66QU7PXatMW5KGHHmLdunW4XC5qamqsNkdhEI2NjRQVFbF+/XruvyGeye/Ec/6x\nwpATtlef+hYlPx4g94khfls3AUCUGA/Z+2cuq16Av/KVr3D69Gm+9rWv8c477/Dd737XapNmkSb7\nuDImefA/RiheY+MjJWH891fG6Ozqsdq0eVRVVfHTn/6Uz3zmM8TExPDpT38at9tttVkKnZFS8uCD\nDzJ89Qr/dWskB+qG+NeTEyEXXTY2NvLtF/u5zWVnc6adz1WN0HfVA0Ca7LfYOt+wVICFEE8LIXqF\nELUztiULIV4WQjRN/U4K9Pxnz57lV7/6FV/+8pfZu3cvn/zkJ3nyySdDqvncK1L5l5pxeq9KntoV\nyS/uiyI+Av7hUOg1+77//e9TVFTEU089xY9+9CPq6+s5cOCA1WYpdKS6ah/7P7uWd999lx980MM/\n3xvOlkwb/+vQOFLKkIoun3jiCWxC8OsHovjlRyIZGocnD48D0CtSLLbON6yOgH8B3D1n2zeAV6SU\nRcArU/8HxK9+9SvcbjcPP/wwAF/+8pcZHh7mN7/5TaCn1JXqqn045DBPH5tge7ad7WvDSIgUPHhj\nJH9oHGVgYMBqE6c5efIk7733Hg899BDh4eE88MAD5OTk8PTTT1ttmkIntPGI3x7tJTlK8JmNYdiE\n4OHtDk73e3ij3dvaCYXocnh4mGeeeYY7b7uJ+JhI1qXYubswjKePTTDkDqdj8yNWm+gTlgqwlPIN\n4OKczfcBv5z6+5fARwI9/3PPPcdNN92E0+kEYNu2bRQXF/Pcc88Fekrd0Jy9q+8ydX0eHtwYjpQw\nQBybP/q3TE66ef755602c5rnnnsOm83Gpz71KQDCwsL42Mc+xksvvcSlS5cstk6hBzk1e7F7xnih\naZL7S8KIChcAPLA+nAg7/Mdp7yB2KESXL7/8MsPDw/z11/+B2i3f4zyp/OWGcM5dkTwb/zmVBREE\n6VLKboCp32kLHSSE+IIQ4ogQ4khfX9+8/W1tbRw7dowHHnhg5mvYtWsXr7/+OkNDQwaZ7xva4NvB\nZq9T//m6MISAMSL5q688Tm5uLi+88IKlNs7kxRdfZMeOHaSkXLv5PvrRjzIxMcGLL75ooWUKvUiT\nffypzc3lMbhv3bUM1RiH4I78MA40TDDsCY3o8sCBAyQkJHDLLbdQsXsPGY81c+/PzmG322m9FG61\neT4TigLsE1LKp6SUW6WUW1NT58/4e+211wC45557Zm3/8Ic/zPj4+PR+q0iT3ofGH1omKU21sTbe\nNrW9HyEEt99+O6+99lpIDHL19vZSXV3NvffeO2t7RUUF8fHxvP7669YYptCVXpHKH5onibDD7fnX\nBHhS2rinMIwzg5KD2X9jeXQppeTgwYPcddddhIdfE9ukpCQqKytXVEAQigLcI4TIBJj63evvCaqr\n9nHwJw+TEi1Ifnb3rFHbnTt34nA4ePPNN/WzOAB6RSpjk5I3293cOcPZtebd7bffzsDAACdOnLDK\nxGm0z+qOO+6YtT0sLIwPfOADlj/MFPrQsfkR3uzwsC3bTvRU98OIdHBsyw+4da93uvSgI9tKEwFv\n67arq4tbbrll3r5bb72V48ePc+XKFQss859QFOAq4MGpvx8E/Bpm1/pWq9uHuDnXTqbon5U6ExkZ\nyZYtWzh06JC+VvtJx+ZHOHzexpgbdubYAa+za8272267DSAkost3332XiIgIbrzxxnn7br31Vhob\nG+nq6rLAMoWelN3xaWrOe9iYE4dHCs6TSu2W71Gxew/r168nOTnZ8sAFmL53b7755nn7Kisr8Xg8\nvPvuu2abFRBWp6H9O/AOsE4I0SmE+BzwA+BDQogm4ENT//tMTs1eLl4ZpXVA8sFcr7DNTZ2prKzk\nyJEjjI6O6vVW/KZi9x6q7N4EkIrssFnODpCVlUVOTk5ILNTy7rvvsnnzZhwOx7x9lZWVABw+fNhs\nsxQ6c/jwYdxuD3d/81+x/cMgGY81T/ujzWbj5ptv5q233rLYSnjrrbdISEigrKxs3r4dO3Zgs9ks\nD7B8xeosiE9IKTOllOFSyrVSyp9LKS9IKW+XUhZN/Z6bJbEkabKP0Un4yxvCZ/VjzUyd2blzJ+Pj\n4xw7dky/NxMAPSMOMjIycD5xaZaza2zdupXq6mqLrPMyMTHBkSNH2LFjx4L7N27ciN1u5+jRoyZb\nptCbd955B4Cbbrppwf3btm2jqanJ8qyXd955hx07dmC32+fti4+Pp7y8XEXAVtErUilItvGvD0Sx\nId0+Y/u10fvNmzcDWN6/+t5777F9+3aEEAvur6iooLm52dJ84JMnTzI6OrqoAEdHR1NaWhoSkboi\nOI4fP05eXh7JyckL7te6oI4fP26mWbMYGxujvr5++h5eiBtvvNHye9tXVp0Ad2x+hBE5u6k8s28V\nIDc3l8TEREsd6dKlSzQ2NlJRUbHoMVu3bgWwVNy0VsKWLVsWPWbr1q0cPXo0pBdtUSzPiRMn2Lhx\n46L7NQG2suV46tQpJicnl7Rz06ZNnD9/nvPnz5toWWCsOgGu2L1nOjF77kCChhCCTZs2WfqUrKur\nA1jSkTTRs/JBUVtbS3R0NHl5eYses2XLFvr6+ujo6DDRMoWeXL16lcbGxiX9MTMzk/T0dEsFWLsX\nlhNgsL6F6wurcj3git17YEpwM6Z+5rJp0yaeeuop3G73gn1JRlNb613+ory8fNFjkpOTycjImBZr\nK3j//fcpKyvDZlv8Wa3dDLW1teTm5pplmkJHamtrkVIuKWzgjYKtFOATJ04QFRVFUVHRosdo7+H4\n8ePcddddZpkWEKsuAvaVjRs3Mjw8THNzsyXXr6urIzY2dlnBKi8vt1SAa2trueGGG5Y8prS0FID6\n+nozTFIYgBYtatHjYmzatIn6+nrGx8fNMGseJ06coLy8fMmgKSkpCafTafkguy9ctwK8YcMGwBvh\nWUFtbe2ykSVAWVkZ9fX1eDwekyy7Rm9vL729vcsKcChE6orgOHHiBPHx8SxXILS0tBS3201LS4s5\nhs1ASrlsP7XGDTfcsCL88boV4OLiYgAaGhosub4mwMtRVlbG8PAwbW1txhs1B1+6STRKS0tVBLyC\nqa+vp7S0dNGMHI3169cD3sEws+nr6+PixYs++WNJSQlNTU0hMZV/Ka5bAY6NjSUnJ8cSAe7r66O3\nt9cnR9JE2oqnudY6WC4ChmuRusqEWJk0NDSwbt26ZY8rKSkBrBFg7V711c6xsTHa20O7qPZ1K8AA\nWWtief+VZ/E8mmBquRVNTENdgOvr61mzZg1paQsuSDeL0tJShoaGVCbECuTy5ct0d3f7JGxa4HL6\n9GkTLJuNvwIMWGKnP1y3AlxdtY/NjjO09I8hkKaWW9GcQmvOLUVCQgJZWVmWRByNjY0UFxcv2ywF\nax8UiuBobGwEfBM28PqtVRFwRESET5k2SoBDnJyavZSnwJVx6B7yNpvNKrfS1NREVFQUWVlZPh1f\nVFRkSbZGU1PTkuk+M9FuXu1mVqwcAhHg06dPmz4w3NDQQFFRkU9po2vWrCElJUUJcKiSJvtYt8b7\n9k/3e2ZsN77cSnNzMwUFBctmQGgUFRXR1NRksFWzGR4e5ty5cz4LcGpqKnFxcZal9ZmJ0bUMzaah\noQGbzUZhYaFPx5eUlHD16lU6OzsNtmw2vvZTa5SUlCgBDlV6RSolKfMF2IxyK83NzT47O0BhYSF9\nfX2mLoKiCamvAiyEsCxSt4BfYEAtw+qqfZx/rND0MYmGhgZcLhcRERE+Ha9lEJn5XU9MTNDa2qoE\neLXQsfkRkmIjiHVAw5QAz10zwgg8Hg8tLS0+CxtcE0EzHV6LuP2xs7Cw0PRI3QqMqGWorWOdQR+T\nHnPHJBoaGqZF1RcKCgoATM0Fbm1tZXJy0i8BXrduHX19fSFV3HYu160AV+zeQ93Wx3EmOWgZ8Cy4\nZoQRdHZ2MjY25lcErImgmeIWqAC3tbUxMTFhlFmhjE+1DGHheoZajcCHXxzF9b+99QrNGJPweDw0\nNjb6JWxr164lPDzcVAH2t58arj0oWltbDbFJD65bAQavCBfv/DBnwosXXI/XCLQo1h8B1hzJbAFO\nT08nLi7O59cUFRXhdrtDPvfSahaqZ6jVCEyNEXQPSYYn5NR2Y8ckenp6GB4e9utBa7fbycvLM1WA\ntWv5c9/k5+cDSoBDmvz8fFpbW00b0dVE1B9Hio6OJjs72/QuCH9uSrj2nq6TfuC5BFXLsFd4hTg/\nyXtLtg16prYbOyahzbBcbgryXAoKCkwV4La2NmJjYxddq3ghlAAHgRCiTQjxvhDiuBDCsAVx8/Pz\nGR0dNW3t0ObmZiIiIli7dq1frzM7EyIYAb4e+oEXIKhahto61nmJ3pzrMwMeU8YktNaK0+n063UF\nBQU0NzebNvOxvb0dp9PpU066RlxcHKmpqZasW+ErISvAU9wmpdwkpdxq1AXM7ifyNwVNw0wBHhoa\n4vz5835F6QDp6enExsau+gjYiFqG2jrWsUneSPj4QIwpYxJaBByIAF+5coX+fuPTNsFrp79ROlxr\n4YYqoS7AhqM1U8x6SjY1NfktbOB1+P7+flPKbWs3pfbZ+IoQ4rrIhDCiliF4Rbh87xmio6PpL/mU\nKWMS7e3tJCcn+9XXD+C54P2Om77hMiVlTouA/cXsrhJ/CWUBlsBLQoijQogvzN250EhyIGjNGjOe\nklJKWltbAxJg7elvxqpogTZLwSvaVqzctloQQpCfn8+ZM2dMuV57e7vfkWV11T5uu/BvAJwZMD5l\n7vLlywwMDAQcAZ89ezZkM3NCWYArpZSbgXuALwohPjhz50IjyYHgcDjIyckxRYB7e3sZGRkJyJHM\nFOBAB2a017S1talV0YIgLy/PtGZzW1ub3w/anJq9rE92I4CWAe9goZEpc8EEBAUFBXg8npDNzAlZ\nAZZSdk397gX2A9uMulZBQYEpDh+MI5kdATscDtLT0/1+rcvlYmRkhGBaJdc7Wr+l0Q8xKWVATfs0\n2UdkmCA7XtB80fhp/MEEBKGeCRGSAiyEiBFCxGl/A3cCtUu/KnDy8/NN6SfSBDgQR0pLSyMqKso0\nAc7NzfV7oBDMfVCsVvLz87l69arhD7H+/n6Gh4f99kctZS4v0TadLufdbkzKXLBdYqAE2F/SgbeE\nECeAw8DvpZR/MOpi+fn59PT0cPXqVaMuAQQ+4gzevkGXy2VK32CgAx6gBFgPNNEw+rsOVNi0lDln\noo32S8ZP429rayMyMtKndannkpWVRURERMgOxIWkAEspW6WUG6d+yqSUjxt5PTMdPiEhgYSEhIBe\nr/WvGk0wAqy9Tglw4OTl5QHGR22BNu21lLk1CTGcuyzp9KQYmjIXSA6whs1mIzc3V/UBhzKaaBj5\nJVVX7aPx5f+LK/JKwGk7eXl5hgubNiklUAGOj48nOTlZCXAQmCXAwTTtK3bvofyv9uKW4P7cq4am\nzAWaA6zhdDqVAIcyRguwttJV9+AozkRbwGk7LpeLgYEBQ5elPHv2LBDYTalhVqS+WomOjiYtLc3w\nz7C9vZ34+HgSExMDer1ZrZ1gWmSgBDjkycjIwOFwGPYl5dTsJZIx2gc9OBO8H3kgaTtm9K8GM1Co\noQQ4eJxO5/TD0Ci0FLRAmvZgTstxeHiYvr6+oAW4p6eH0dFRHS3TByXAePuJcnJyDHOkNNnH4Ki3\n/JErUczY7l/ajpkCrEcErHKBA8eMqC2QSRgz0WqzGWmnHgGB5stGP9ACQQnwFEZGHL0idTpdR4uA\nvdv9S9vR+gaNFmCbzUZ2dnbA51C5wMGTm5vL2bNnDX2IBTIJYyaRkZFkZGSEfEBgRqQeKEqApzAy\n4ujY/AiNg96P2pno/R1I2s6aNWuIiYkx3OGzs7MJDw8P+BwqFS14nE4nIyMjhi12Mzg4yOXLl4MS\nNjA+Ug9mEoaGEuAVQG5uLt3d3YyPj+t+7ordezgc7y0hlptgC7j6hhm5wMEOeIASYD0wWjT0EDbt\n9UZ3QYSHh5OZmRnwObKzs7HZbEqAQxmn04mUko6ODkPOL+PWEh0dTeoPLwVVfcPoAa5gm6WgcoH1\nwOj+VT2a9trrz549a1hBg7a2toBnZWqEh4eTnZ2tBDiUMSPiCGbEWcPIiGNycpJz584FHRWpXODg\nMXrgSI/BLfDaOT4+blhBAz1aZBC6qWhKgKcww+GDdXbw2jk4OGhILvC5c+dwu926OLxKRQuOpKQk\nYmNjDQ0IoqKiSEkJbv0GzaeNtFOv+0YJcAiTk5ODEMLQJp9ewqadT2/0apZq5whFh18pCCGmMyGM\nQAsIgm2RGdlyHBsbo7u7Wzd/7OzsZHJyUgfL9EMJ8BQOh4PMzExDHGloaIgLFy7o5kigf/9qddU+\nTjzxMQCiqz4f9OLaTqdT5QIHiZEPMT36+gH6a/8IwJl/+YzulTH0mJWp4XQ6cbvddHV1BX0uPVEC\nPAOjFu3QM7I0IgLWpkpr3RpbEgaDrnDgdDoZHh7mwoULepl53WHkIjJ6dIlVV+1jW/33WBMlOHvJ\no3tlDL36qWeeI9RaZUqAZ2BUxKGnI6WmphIVFaWrnTk1e4kS47QNekiLEUSFi6ArHISqw68knE4n\nFy5c0H2ZVL1aZJrfOBMF7Ze8LR09K2MEs3zrXEI1F1gJ8AycTicdHR26p9To6UhCiOnmvV6kSe+M\ntfZLHpwJgU+VnolKRQseowaG9WqRaX7jTJi9MLtelTHa29ux2+2sXbs26HOZMW06EJQAz0BLqenp\n6dH1vFqJn4yMDF3Op3ekrlU4aB+UuBIDnyo9k1CNOFYSRomGXpMwNL9xJngXZtf6+/WqjKHNygwL\nCwv6XFFRUaSlpYWcPyoBnoFRohFMiZ+F0DsC7tj8CFc94Zy9dG21tmArHCQlJREXFxdyDr+SCPUI\n+FplDMHwBFwYkbpWxtArBU0jFDNzQlaAhRB3CyEahBDNQohvmHFNIwVYj+4HDZfLRX9/v259gxW7\n9/BGwd8x5g5uqvRMtK6SUHN4o9HTb7OysrDb7Yb4ox4tMq0yRnyCdz3ho4OJulbG0Pu+CUV/DEkB\nFkLYgX/EW5K+FPiEEKLU6Osa2eTT25FAXzuT1n0QANdDzwY1VXomekfqoY7efqv1fxrhj3q1yCp2\n72HT118A4OrdP9ZNfCcmJujs7NQ9AjZ6hTl/WfYbWMiBhBC3GmLNNbYBzVO14caB3wD3GXzN6eoA\nejp8sCV+FsKIDAM9U+U0rI44hBBfEkIkmXhJ3f3WiGVS9ZqVqWGEP547dw6Px6O7P4baMqm+PAKf\nFUJ8XXiJEkI8CfxPg+3KBmauitM5tW0aIcQXhBBHhBBH9PxA9RYNbXGfUI+AjRBgl8tl2LRpH8kA\nqoUQz051DQQ37Wt5lvVb8M93jXiI6d0iM2LatJ6ZQxqhmJnjiwBvB3KAt4FqoAuoNNIoYKEbZVa7\nQUr5lJRyq5Rya2pqqm4X1nuxGz1n82hkZmYSHh6uqyO1t7eTmJgYcMXmhbA6E0JK+S2gCPg58Bmg\nSQjxfSFEgUGXXNZvp+zy2Xdzc3M5d+6cblNoR0ZG6Onp0TUCNqK/X8/ceQ2r/XEhfBHgCWAEiAIi\ngTNSSmPWnrtGJ17R11iLV/gNR3MkvfqJjIgsjSi1rfeAB4SGw0vvF3l+6mcSSAJ+J4T4oQGX091v\n9Z5Ca0RAoJ3PiAg4Jydn6QP9IBT8cS6+CHA1XgGuAG7GO7DwO0Ot8l6zSAiRJ4RwAB8Hqgy+JuD9\nkq5cucLg4KAu52tvb0cIoUsy+Uz0HuAyQoCtng0nhPhrIcRR4IfAIeAGKeV/A7YA/8WAS+rut3qL\nhhEBgXY+vf0xKyuLiIgI3c6ZmJhIfHy8bp/l5OQkaWlp/OQnPwn4HL4I8OeklN+RUk5IKc9LKe8D\nDgR8RR+QUk4CXwIOAqeAZ6WUdUZeU0PvfiLNkYIp8bMQenaVSCl17xcESEtLIzIy0so+txTgASnl\nXVLK30opJwCmWnC79L6YEX5rlADr2bQHr50DAwNcuXJFl/MZ4Y+g733T1dVFX19fUA+JZQVYSnlk\ngW2/CviKPiKlfEFKWSylLJBSPm709TSMcHgjHMnpdNLd3a1Lqe2BgQGGhoZ0t1NbUtHCPuDvSCkX\nvLiU8pRB19TVb7XUSL0eYm1tbdjtdrKysnQ5n4YR943eDwnQt6tEj9ZESOYBW4nejnT27FnDnuSA\nLiWUjGqWaucMpT63lUZUVBTp6em6ikZOTo4u03tnoud943a7DbtvlACHOCkpKURHR+vyJXk8Hjo6\nOgxzJNDH4Y0UYFUZI3j07F81qmmvpz92d3czOTlpWAR86dIlXVIjtfeqtVICQQnwHPRMqenu7mZi\nYiKoL2gx9Kw8bFS/IHgdvq+vj+HhYd3Pfb2gZ7+lUU37jIwMHA5HyAcEegcuKSkpxMTEBHwOJcBz\nqK7aR8ZEG23v/EfQK/wb6UjZ2dm6rRPQ1tZGdHR00PXBFsLoWnvXA1pAEOwyqePj45w7d84Qf7TZ\nbOTk5Ojmj2BcQAD6CXCwn6US4BlolSGKEyZpH5RBr/BvpACHhYWxdu1aXSJgvSo2L4TVqWirAZfL\npcsyqZ2dnUgpDRE20C9S16Npvxh6ZjkpAdaZ6RX+E2xcGJFcHZdBrfBvVNK7hl5dJUY1SyE0p3+u\nNPT6DI0MCLTz6hUBp6amEh0drYNVs9FSI4O1U0qpy0ChEuAZaCv8a4uSt1/yTG0PbIX/9vZ2kpOT\niY2N1cfAOeg1OKP3uqszycrKIiwsTEXAQaBXK8KI9RVmoldqpJH+qNcYT19fHyMjI0qA9WR6hf9E\nb1O8farMSqAr/GsLsRuFy+Xi3LlzTExMBHyOy5cvMzAwYNhNabfbdesbvF7Rq9+yra1tuq/WCDQ7\ng02NbGtrIy8vTw+TFkQPAdarNaEEeAbTK/xPVYVoGwxuhX+jJmFoeAbavKluX0sOeMDQyAwIjett\nXWC9iY2NJTk5OejP8MyZM2RnZ+NwOPQxbA56PCg8Ho+hXWKgrwAHa6cS4BloK/yLuDTCbVB/KTLg\nFf6llIYKcHXVPnYOemeEB1MS3Oh+Qe3cKgIODj0GuMyILCE4AT5//jzj4+OGC3Bvby8jIyMBn0NF\nwAZRsXsPWf/QQo4rn/6cuwNe4X9wcNCQ6b0aOTV7KU7ydpFoXSWBDBgamfKj4XQ66erqYnx83LBr\nrHb0aEUY2bcKsHbtWmw2W1ACfObMGcB4f4TgUiPb29uJi4sjMTExKFuUAC9CsBGHkak04B0wzIkX\nCLxdJde2+zdg2N7eTkREBGlpaTpbeA2Xy4WUUpdp09crmj8Gukzq+Pi47iV+5hIeHk5WVlZQ9432\nkAn1SF1r3QabuqkEeBGCiTiqq/Zx/Af3ABB78G+CmsyxGL0ilYgwQWacmM7W8G73b8BQywHWq2Lz\nQoTiOqwrDafTyfDwMP39gWXkdHR0IKU0VNgg+O4mozM1Zp5bDwEOFiXAi6Cl1IyNjfn1Om0yx+VL\nAwBsTrwU1GSOxZg5YNg21QURyICh0QOFoARYD4JNRTOjqwn0EeD09HSioqJ0tGo2elSbVgJsMIGm\n1GiTOc4MSKLDITVaBDWZYzG0AcOMxCjaL8mAS8kb3S8I3qoGQgglwEEQ7GQMM/pWwWtnZ2dnwCWU\njB4oBO8s0pycnIA/y8HBQQYHB3WxUwnwIgQatWmTOVoHPeQn2ab7iAKdzLEUFbv3sG7Xl+gYspP6\n7Qa/xXd4eJi+vj7Db0qHw0FWVpZKRQsCPSJgrcy9kbhcLiYnJwMuoXTmzBnD/RGCi9S1h1l+fn7Q\ndigBXoRAHV6bzNE64KEgyTZju/4L3YDXzomJCbq7u/1+rRkpaBoqFS04tHI6gT7E2traDFkHeC7B\ndDdp6wCHugC3trYCq1SAhRCPCSHOCSGOT/3ca4UdWkqNvw7fsfkRhj3htA54I2AIrG/WV4JxeCXA\nK4tgMnPMjCwhMH/Ulm81y85AZ5FqAryauyCekFJumvp5wQoDtJQafwW4Yvce3ij8OsMTkJdoC7hv\n1leCWRe4paUF0OdJvhwul4uOjg7cbrfh11qtBJOZY0ZfP1xLuwxEgM1IQdNwOp14PB46Ozv9fm1L\nSwtr1qwhISEhaDtCVYBDgvz8/OmnnT/EF1YCUPDl58h4rNkw8YXgHL6lpYWoqCgyMzP1NmseTqcz\nqL5BhfchdubMGb9zgcfGxujq6jJF2KKjo0lLS5vuJ/UHswYKAQoKCgACur9bW1t1C1pCVYC/JIQ4\nKYR4WgiRtNABQogvCCGOCCGO9PX1GWJEUVERzc3Nfr9Ozz6i5YiOjiY1NTUgAW5ubqagoMCQdYDn\nolLRgqewsJChoSF6e3v9ep3V045bAAASZ0lEQVSZXU3gFTetdeUPmgAbuYCVRmFhIUDA9/eKFmAh\nxB+FELUL/NwH/BQoADYB3cCPFjqHlPIpKeVWKeXW1NRUQ+wsLCykp6fH71LbmgCb8STXrhNoF4Tm\niEajZwml65VARUM73qzvOtDApbm5mZycHCIjIw2wajZZWVlERkbS1NTk1+smJydpb29f2QIspbxD\nSlm+wM8BKWWPlNItpfQA/wJss8JGuOaw/j7NW1tbyc7ONsWRILABLo/HY6oA611e/XqkqKgI8F+A\nNZHRXm80hYWFdHZ2+l0HsLm52TR/tNlsFBQU+P1ZajnOK1qAl0IIMbND8n6g1ipbAo049Gyi+EIg\n6wR0dXUxNjY23RdmNNHR0WRmZgbUNA0lhBAfE0LUCSE8Qoitc/Z9UwjRLIRoEELcpfe1XS4Xdrvd\n76itubmZ+Ph4jGopzkUTen/7V5uamkx7SEBgkbr2nvS6b0JOgIEfCiHeF0KcBG4D/tYqQ7QPOZAv\nySxhA++NOTo66lcusNnNUoDi4mIaGxtNu55B1AIPAG/M3CiEKAU+DpQBdwP/JISw63nh8PBwXC5X\nQBFwYWGhKX39cM2n/HlQDA4O0t/fb6o/FhYW0tLS4lexU73Hd0JOgKWUn5ZS3iCl3CCl3C2l9H+G\ngU7ExcWRnp7ulyONjo5y7tw5U0acNYqLiwH8EjctEjXzQbEaBFhKeUpK2bDArvuA30gpx6SUZ4Bm\nDOg+KywsDCgCNjOyDKTlqB1rtp2jo6N+Zea0trZOF8TVg5AT4FCjsLDQL0fSbg5NFM1g3bp1ADQ0\nLKQLC9Pc3Ex4eLhh5WkWori4mP7+fi5evGjaNU0kG5i5cEjn1LZ5BJPBozWbfe1umpiYoK2tzdTI\nMjExkZSUlIDuG7MjYPDvQdHY2EheXh52uz6NGyXAy+BvP5EmgpoomsHatWuJioryOwLOy8szfGrq\nTLSHkr8RnNksk6Wz6MsW2LagSgaTwVNYWMjly5fxRbirq/ZR/ZUC3G43abVPGbIs6mIUFRX59T1r\n95iZLbJABLihoYH169frZoMS4GUoLCykq6uLq1ev+nT86dOnAXMjYJvNRlFRkd8RsJnODtceSqHe\nDbFUls4SL+sEZjYn1gK6zzrxVTS0ZVEHL3oXgdq65qohy6IuRiAtRy2QMIu1a9ficDh8ttPtdtPY\n2KhrcKUEeBk0h/d1RLehoYGcnBxiYmKMNGse69at81mAPR4PDQ0NlJSUGGzVbLSmW6gLcIBUAR8X\nQkQIIfKAIuCw3hfR+kiXiy61ZVGbL3oHmAqTbYYsi7oYhYWFdHR0+Fx3zewMCPBW7M7Pz/dZgNva\n2hgfH9f1vlECvAyaU2iR7XKcPn3a1O4HjXXr1nHmzBmf6q6dPXuW4eFhXZtSvuBwOMjLy1vRAiyE\nuF8I0QncBPxeCHEQQEpZBzwL1AN/AL4opdR94QtfU9G0ZVEb+j3ER3jXpfZu139Z1IXQ7htf0g6l\nlDQ2NpouwOBtqfp6b2sBjhJgEykpKUEIQV1d3bLHSiktiSzBK8But9snh6+vrwegtLTUaLPmsdIz\nIaSU+6WUa6WUEVLKdCnlXTP2PS6lLJBSrpNSvmjE9R0OB4WFhdPf4WJoy6LW9XkoS7VPp6AZtSzq\nXLSH+6lTp5Y9tqenh4sXL1rij2VlZTQ0NPgUuGhCrbogTCQ6Opr8/HyfBLi7u5srV65YEgFrfc6+\ndENoN4XZETBcE2B/ci8VsykrK6O2dun5SVrJKq8AG78s6lxKSkqw2WzL2glM31vl5eVGmzWPsrIy\nJicnfRowPH36NCkpKaxZs0a36ysB9oHy8nKfBNiIJoqvaKLvS3Oqvr6e9PR0kpOTjTZrHuvXr2d4\neFgtyhME5eXltLS0LNm/WrF7D28U/B39w5LSVLvhy6LOJTIykqKiIr8EuKyszGiz5qFd09f7W+97\nWwmwDySFj9F4+hQjfx/P+ccKFx1J1r5EKwQ4ISGBnJwcTp48ueyxp06dsiT6BdiwYQOAT3YqFqa8\nvByPx7Psw9aR450pXf61KsOXRV2I8vJynwU4OTmZ9PR0E6yajRapLyfAUkrq6+uVAJtNddU+bnG/\nhVtC80UPGfQtms5z4sQJ1qxZQ3b2gvn3hrNx40ZOnDix5DGaI1nR3wbem1IIoQQ4CGSvVyxO/o+d\nSwYEmvhZEVmC97tubm5eNhOirq6OsrIy06ZKzyQyMpKCgoJlBbirq4v+/n42btyo6/WVAC9DTs1e\nNqd78+nr+rz9loul8xw/fpyNGzda4kjgFeCGhgZGR0cXPaajo4NLly5Z0t8GEBsbS0FBgRLgAKmu\n2sfd3f8Hhx3qe5cOCOrq6khMTDRlwf2F8CVSl1JSV1dnmT+Cb33qWmCzadMmXa+tBHgZ0mQf69bY\nsAt4v8c9Y/vsdJ7JyUlqa2t1/4L8YePGjbjd7iWf5jU1NQBs3rzZLLPmsWHDBiXAAZJTs5f4sAlK\nUmzLBgTvv//+dIvDCrTIeylx6+zsZHBw0HIBbm5uXjJwOX78OHCtC00vlAAvQ69IJSJMUJpqo+a8\ne8b22ek8TU1NjI6O6t5E8Qft2kt1Q9TU1GCz2bjhhhvMMmseGzZsoKmpye/1YhXX8ntvSLNz7PzS\nAcGxY8fYsmWLqfbNpKioiMjIyGnxWogjR44AWGrn5s2bcbvdS943x48fJz8/n/j4eF2vrQR4GbR0\nnm3Zdg6f8yClXDCdR3MyKwW4oKCA6OjoJR3p2LFjrF+/nujoaBMtm82GDRuQUqooOAC0/N5t2Ta6\nrkg6L3umts8OCE6dOsXIyAgVFRWm26gRFhbGjTfeyHvvvbfoMUeOHCEsLEz3yNIftm3zLlp3+PDi\nExdPnDhhyL2tBHgZKnbvoXbL91iXncjFEcl7A0kLpvNUV1cTGRlpWXYBeKdW3njjjUs6Uk1NjaXd\nDwDbt28H4N1337XUjpWIFhBsz/auxvVep3vBgKC6uhqArVu3zjuHmWzfvp2jR48uWv69urqa8vJy\nU9eAmEt2djaZmZnTn9lcBgYGaGxsNOS+UQLsAxW79/Ch774EwJmbfrBgOs/bb79NRUUFDofDbPNm\nUVlZydGjRxcceW5vb6erq8vSqAi89bhyc3N5++23LbVjJaIFBBkZGTjs8Oq5iAUDgiNHjhAfH2/J\n9N6ZbN++ndHRUd5///15+6SUHDlyxHJ/FEKwbdu2RQMXLVCorKzU/dpWFeW0rKxLoGhP6YWaUyMj\nI9TU1BjyBflLZWUlExMT031rM3nzzTcB+OAHP2i2WfPYuXMn77zzjtVmrEgqdu/B+b0WNm3ZRm3Y\nhgUDgkOHDrFt2zZsNmtjLK21s9B9c+rUKQYGBqaPsZKKigoaGhoYGBiYt+/tt9/GbrdPd1XoiVXf\njmVlXQIlLCyMHTt28Prrr8/bV11dzcTEBDt37jTfsDloNhw6dGjevjfffJOEhARLR5w1brrpJjo7\nOzl79qzVpqxYdu7cyeHDh+e1dvr6+jh58iR/9md/ZpFl13C5XGRkZPDGG2/M2/fqq68ChISdH/jA\nBwD405/+NG/foUOH2LRpkyErHFpVFdnSsi6Bcuedd3LixAnOnz8/a/tLL72E3W7n5ptvtsiya6Sk\npFBaWsorr7wyb99rr71GZWWlbqv5B4N20x08eNBiS1Yud955J6Ojo9MtGw0tSLjtttsssGo2Qgg+\n9KEP8fLLL+N2z14c7rXXXsPlcplavmsxduzYQUxMDC+//PKs7UNDQxw6dIhbb73VkOuGWh+wz2Vd\nrODOO+8EmPclvfDCC+zcuZOkpCQrzJrHrl27eP3117l06dL0ttOnT9PU1MS9995roWXXKCsrIzc3\nl9///vdWm7JiueWWW4iIiJj3EDt48CBxcXGWD8Bp3H333Vy4cIGjR48C3skkZ79dwKsvPM9NiRdM\nrdSxGA6Hg9tuu42DBw/OKvf06quvMj4+zoc//GFDrmuYABtd1iWYulqBsmnTJjIzM/nd7343va2t\nrY1jx46FjLAB7N69m8nJSV588dqKiAcOHJjeFwoIIdi1axd//OMffa42ophNdHQ0t956K/v378fj\n8UwL2/O//jkfckmOvfBzq00EvIGL3W7n+eefn67U8X5LN4Oj8JfrJ02t1LEUu3btoqWlZVbe8v79\n+4mLizNufEdKadkP8Dqwdcb/3wS+OeP/g8BNy51ny5Yt0iweeeQRGRYWJnt6eqSUUj766KNSCCHb\n29tNs2E5JicnZXZ2trzjjjuklFK63W5ZXFwsd+zYYbFls3njjTckIH/2s58tegxwRFroo0b/BOu7\nv/71ryUg/+m7fyuHv5Mi9/9FlARk1cej5PB3UuThA/8c1Pn1YteuXTIzM1N2fDtfykfj5V+UhcnE\nSOTYt+KkfDRedj9aYLWJ8sKFC9LhcMiHH35YSinl5cuXZUxMjPz85z/v97l89dtQE+Ay4AQQAeQB\nrYB9ufOYKcCnTp2SQgj51a9+VQ4ODsqUlBR5zz33mHZ9X/n+978vAVldXS2ff/55CchnnnnGarNm\n4fF4ZHl5uVy/fr0cGxtb8BglwEszPDwsk5OT5Qfzo+Tkt+NkRZZNuhKFHA8hYZNSyqqqKgnIp/48\nUp7+Yoy0CeTXbnJI+Wi8lI/GS/d3Eqw2UUop5Sc+8QkZExMju7u75eOPPy4B+d577/l9npAWYOB+\nvP27Y0APcHDGvr8HWoAG4B5fzmemAEsp5Wc/+1lps9lkSUmJtNvtsrq62tTr+8LAwIDMysqSmZmZ\nMikpSZaXl8vx8XGrzZrHf/7nf0pAfvKTn1xQhJUAL89PfvITCcjyNJsE5C8/EhlywubxeGRlZaWM\ncQjpTBAyKRLZ/dXYaTtD5UHR0NAgHQ6HLCoqkuHh4fL+++8P6Dy++q1VWRCWlnUJlieffJKPfvSj\nTE5O8swzz4TMYMdMEhMTOXDgAJmZmZSWlrJ//37Cw8OtNmseu3bt4vHHH2doaCgksjNWIl/84hf5\n4s5EhsYlj90Swac3XPuezSpBtBxCCJ599lnWlxQTG2Fj/19EkxFrfqWO5SguLua3v/0tNpuNu+++\nm5//3Nh+dOEV65XN1q1b5UITDxQrB4/Hs+CkASHEUSll6D3hdEIv39UGt6LEtdpmI9JhahUMX6mu\n2kdOzV7SZD+9IoWOzY+EnI3B4qvfhplhjEKxHFbP2FrpVOzeQzXMFrYtoSlsFbv3wJRdGVM/1ytK\ngBWKVYIStpWHCjsUCoXCIpQAKxQKhUWsikE4IUQfsFCd8xSgf4HtK5nV+J5g8ffllFKmmm2MWSzi\nu9fbd7zSWeh9+eS3q0KAF0MIcWS1jaCvxvcEq/d9BcJq/SzU+5qP6oJQKBQKi1ACrFAoFBax2gX4\nKasNMIDV+J5g9b6vQFitn4V6X3NY1X3ACoVCEcqs9ghYoVAoQhYlwAqFQmERq1KAhRB3T1VVbhZC\nfMNqe/RCCNEmhHhfCHFcCLFiVx8SQjwthOgVQtTO2JYshHhZCNE09Ts06juZjPLd0EZv3111AjxV\nRfkfgXuAUuATU9WWVwu3SSk3rfB8yl/grXo9k28Ar0gpi4BXpv6/rlC+uyL4BTr67qoTYLxVlJul\nlK1SynHgN3irLStCBCnlG8DFOZvvA3459fcvgY+YalRooHw3xNHbd1ejAId0ZeUgkcBLQoijQogv\nWG2MzqRLKbsBpn6nWWyPFSjfXZkE7LurcTlKnysrr0AqpZRdQog04GUhxOmpJ7JidaB89zpjNUbA\nnUDOjP/XAl0W2aIrUsquqd+9wH68TdbVQo8QIhNg6nevxfZYgfLdlUnAvrsaBbgaKBJC5AkhHMDH\ngSqLbQoaIUSMECJO+xu4E6hd+lUriirgwam/HwQOWGiLVSjfXZkE7LurrgtCSjkphPgScBCwA09L\nKessNksP0oH9Qgjwfm//JqX8g7UmBYYQ4t+BW4EUIUQn8CjwA+BZIcTngLPAx6yz0BqU74Y+evuu\nmoqsUCgUFrEauyAUCoViRaAEWKFQKCxCCbBCoVBYhBJghUKhsAglwAqFQmERSoBXEEKIRCHEQ1bb\noVD4g/LbxVECvLJIBJQjK1Yaym8XQQnwyuIHQMHUmqp7rTZGofAR5beLoCZirCCEEC7g/0kpyy02\nRaHwGeW3i6MiYIVCobAIJcAKhUJhEUqAVxZXgDirjVAo/ET57SIoAV5BSCkvAIeEELVqMEOxUlB+\nuzhqEE6hUCgsQkXACoVCYRFKgBUKhcIilAArFAqFRSgBVigUCotQAqxQKBQWoQRYoVAoLEIJsEKh\nUFjE/wcC1qtMykWjBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c29207668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#now plot some stuff\n",
    "fig, ax = plt.subplots(1,2, figsize=(5, 2.5))\n",
    "ax[0].plot(t0_guess, x - xleap, 'o')\n",
    "#print(session.run(x))\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('$\\Delta x$')\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('$\\Delta y$')\n",
    "ax[1].plot(t0_guess, v - vleap, 'o')\n",
    "fig.suptitle('Differences Between Python and Tensorflow Model')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(5, 2.5))\n",
    "ax[0].plot(t0_guess, xleap, 'o', label='python')\n",
    "ax[0].plot(t0_guess, x, 'o', label='tf')\n",
    "ax[0].plot(plot_t_obs_values, xleap_plot, 'k-')\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('x')\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('y')\n",
    "ax[1].plot(t0_guess, vleap, 'o')\n",
    "ax[1].plot(t0_guess, v, 'o')\n",
    "ax[1].plot(plot_t_obs_values, vleap_plot, 'k-')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the gradients to show Tensorflow, Autograd, and Finite Differences generate the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python loglikelihood is: -206.48631941943643\n",
      "Tensorflow loglikelihood is: -206.48631941943646\n"
     ]
    }
   ],
   "source": [
    "print('Python loglikelihood is: {0}'.format(python_loglikelihood))\n",
    "print('Tensorflow loglikelihood is: {0}'.format(tensorflow_loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of Negative Log Likelihood\n",
      "  TensorFlow  Autograd  FiniteDifference \n",
      "k  -910.590   -910.590   -910.590\n",
      "x0  -23.758   -23.758   -23.758\n",
      "v0  40.665   40.665   40.665\n"
     ]
    }
   ],
   "source": [
    "keys = ['k', 'x0', 'v0'] + ['tobs']*nobspoints\n",
    "print('Gradients of Negative Log Likelihood')\n",
    "print('  TensorFlow  Autograd  FiniteDifference ')\n",
    "for tg, ag, fg, k in zip(grads_tensorflow[0:3], grads_autograd[0:3], grads_finite_difference[0:3], keys[0:3]):\n",
    "    print('{0}  {1:0.3f}   {2:0.3f}   {3:0.3f}'.format(k, tg, ag, fg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of Negative Log Likelihood\n",
      "  TensorFlow  Autograd  FiniteDifference \n",
      "tobs   -23.906    -23.906    -23.906\n",
      "tobs   -105.840    -105.840    -105.840\n",
      "tobs   -33.586    -33.586    -33.586\n",
      "tobs   -104.049    -104.049    -104.049\n",
      "tobs   -120.278    -120.278    -120.278\n",
      "tobs   -50.893    -50.893    -50.893\n",
      "tobs   -212.029    -212.029    -212.029\n",
      "tobs   -266.304    -266.304    -266.304\n",
      "tobs   -137.818    -137.818    -137.818\n",
      "tobs   -146.409    -146.409    -146.409\n"
     ]
    }
   ],
   "source": [
    "print('Gradients of Negative Log Likelihood')\n",
    "print('  TensorFlow  Autograd  FiniteDifference ')\n",
    "for tg, ag, fg, k in zip(grads_tensorflow[3].values[::-1][:-1], grads_autograd[3:], grads_finite_difference[3:], keys[3:]):\n",
    "    print('{0}   {1:0.3f}    {2:0.3f}    {3:0.3f}'.format(k, tg, ag, fg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.63132932 9.06423057 9.73211192]\n",
      "The value is: -206.48631941943646\n",
      "The gradient is: [910.58954757  23.75812671 -40.66525166]\n"
     ]
    }
   ],
   "source": [
    "# First we say that we want the model to return the value and gradient\n",
    "# of `log_prob` as a function of the parameters \n",
    "\n",
    "from helpers import TFModel\n",
    "model = TFModel(ll, [k_tf, x0_tf, v0_tf])\n",
    "\n",
    "# Within the session, you first need to call the `setup` method.\n",
    "model.setup(session)\n",
    "\n",
    "# You can access the current parameter vector for the model.\n",
    "# This will always be a flat numpy array.\n",
    "params = model.current_vector()\n",
    "print(params)\n",
    "# The value and gradient of the tensor can be evaluated for specific\n",
    "# values of the parameters.\n",
    "print(\"The value is: {0}\".format(model.value(params)))\n",
    "print(\"The gradient is: {0}\".format(model.gradient(params)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: [2.6313293234440556, 9.064230565740932, 9.732111920373985]\n",
      "Initial log likelihood: -206.48631941943646\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "  Objective function value: 8.628458\n",
      "  Number of iterations: 14\n",
      "  Number of functions evaluations: 18\n",
      "Final log likelihood: -8.628457685233188\n",
      "\n",
      "Final parameters: [2.975277023636554, 9.933545619065734, 9.405778661050611]\n",
      "True parameters: 3.0 10.0 10.0\n"
     ]
    }
   ],
   "source": [
    "opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "    nll, var_list=[k_tf, x0_tf, v0_tf])\n",
    "\n",
    "\n",
    "print(\"Initial parameters: {0}\".format(session.run([k_tf, x0_tf, v0_tf])))\n",
    "print(\"Initial log likelihood: {0}\".format(session.run(ll)))\n",
    "opt.minimize(session)\n",
    "\n",
    "print(\"Final log likelihood: {0}\\n\".format(session.run(ll)))\n",
    "params = session.run([k_tf, x0_tf, v0_tf])\n",
    "print(\"Final parameters: {0}\".format(params))\n",
    "print(\"True parameters: {0} {1} {2}\".format(k_true, x0_true, v0_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/tmp/leapfrog/1\")\n",
    "writer.add_graph(session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emcee: Exception while calling your likelihood function:\n",
      "  params: [ 2.95562224 10.1314648   9.18109745]\n",
      "  args: []\n",
      "  kwargs: {}\n",
      "  exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/emcee/ensemble.py\", line 519, in __call__\n",
      "    return self.f(x, *self.args, **self.kwargs)\n",
      "  File \"/Users/landerson/ahw2018/shoderivz/helpers.py\", line 380, in value\n",
      "    return self.session.run(self.target, feed_dict=feed_dict)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f41ff9e497d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0memcee_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0memcee_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/emcee/sampler.py\u001b[0m in \u001b[0;36mrun_mcmc\u001b[0;34m(self, pos0, N, rstate0, lnprob0, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         for results in self.sample(pos0, lnprob0, rstate0, iterations=N,\n\u001b[0;32m--> 172\u001b[0;31m                                    **kwargs):\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, p0, lnprob0, rstate0, blobs0, iterations, thin, storechain, mh_proposal)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mS0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     q, newlnp, acc, blob = self._propose_stretch(p[S0], p[S1],\n\u001b[0;32m--> 259\u001b[0;31m                                                                  lnprob[S0])\n\u001b[0m\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0;31m# Update the positions, log probabilities and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m_propose_stretch\u001b[0;34m(self, p0, p1, lnprob0)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Calculate the proposed positions and the log-probability there.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnewlnprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Decide whether or not the proposals should be accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m_get_lnprob\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# Run the log-probability calculations (optionally in parallel).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlnprobfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/emcee/ensemble.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ahw2018/shoderivz/helpers.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self, vector)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_to_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import emcee\n",
    "\n",
    "emcee_time = time.time()\n",
    "\n",
    "model.setup(session)\n",
    "\n",
    "pos = model.current_vector()\n",
    "pos = pos + 1e-5*np.random.randn(8, len(pos))\n",
    "nwalkers, ndim = pos.shape\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, model.value)\n",
    "pos, _, _ = sampler.run_mcmc(pos, 200)\n",
    "sampler.reset()\n",
    "pos, _, _ = sampler.run_mcmc(pos, 1000)\n",
    "emcee_time = time.time() - emcee_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(sampler.chain[:, :, 1].T, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "true_params = [k_true, x0_true, v0_true]\n",
    "truth = np.array(true_params)\n",
    "# truth[-1] = np.log(true_params[-1])\n",
    "corner.corner(sampler.flatchain,\n",
    "              labels=[\"k\", \"x0\", \"v0\"],\n",
    "              truths=truth);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.var(sampler.flatchain, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "# We will cheat a little bit and use our previous chain to estimate the\n",
    "# the appropriate tuning scales for the parameters.\n",
    "metric = helpers.DiagonalMetric(3, np.var(sampler.flatchain, axis=0))\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "\n",
    "# We will cheat a little bit and use our previous chain to estimate the\n",
    "# the appropriate tuning scales for the parameters.\n",
    "metric = helpers.DiagonalMetric(3, np.var(sampler.flatchain, axis=0)*10)\n",
    "\n",
    "nuts_time = time.time()\n",
    "\n",
    "\n",
    "# This method does the sampling:\n",
    "nuts = helpers.tf_simple_nuts(\n",
    "    session,\n",
    "    ll,\n",
    "    [k_tf, x0_tf, v0_tf],\n",
    "    500,          # The number of MCMC steps\n",
    "    0.1,           # The integration step size\n",
    "    metric=metric  # The scaling metric computed above\n",
    ")\n",
    "nuts_time = time.time() - nuts_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corner.corner(nuts[0],\n",
    "              range=[(np.min(v), np.max(v)) for v in sampler.flatchain.T],\n",
    "              labels=[\"m\", \"b\", \"log(s)\"],\n",
    "              truths=truth);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nuts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
